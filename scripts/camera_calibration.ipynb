{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import cv2.aruco as aruco\n",
    "import os\n",
    "import numpy as np\n",
    "import subprocess\n",
    "\n",
    "calib_id = \"05-08-25\"\n",
    "calib_base_folder = f\"/home/arclab/catkin_ws/src/Catheter-Perception/camera_calibration/{calib_id}\"\n",
    "# Camera 0 refers to top camera, Camera 1 refers to bottom camera\n",
    "# Ensure camera port ids are correct\n",
    "# port_ids = [0, 2]\n",
    "cam0_device = f\"/dev/cam0\"\n",
    "cam1_device = f\"/dev/cam1\"\n",
    "\n",
    "# Ensure proper camera configurations\n",
    "cam0_focus_value = 35\n",
    "cam1_focus_value = 75\n",
    "config_commands = {cam0_device: [\n",
    "                    f\"v4l2-ctl -d {cam0_device} -c focus_automatic_continuous=0\",\n",
    "                    f\"v4l2-ctl -d {cam0_device} -c auto_exposure=3\",\n",
    "                    f\"v4l2-ctl -d {cam0_device} -c focus_absolute={cam0_focus_value}\",\n",
    "                    # f\"v4l2-ctl -d {device} -c exposure_time_absolute=333\",\n",
    "                    # f\"v4l2-ctl -d {device} -c gain=0\",\n",
    "                    # f\"v4l2-ctl -d {device} -c white_balance_automatic=0\",\n",
    "                    # f\"v4l2-ctl -d {device} -c white_balance_temperature=4675\",\n",
    "                    # f\"v4l2-ctl -d {device} -c brightness=128\",\n",
    "                    # f\"v4l2-ctl -d {device} -c contrast=128\",\n",
    "                    # f\"v4l2-ctl -d {device} -c saturation=128\",\n",
    "                    ],\n",
    "                cam1_device: [\n",
    "                    f\"v4l2-ctl -d {cam1_device} -c focus_automatic_continuous=0\",\n",
    "                    f\"v4l2-ctl -d {cam1_device} -c auto_exposure=3\",\n",
    "                    f\"v4l2-ctl -d {cam1_device} -c focus_absolute={cam1_focus_value}\",\n",
    "                    # f\"v4l2-ctl -d {device} -c exposure_time_absolute=333\",\n",
    "                    # f\"v4l2-ctl -d {device} -c gain=0\",\n",
    "                    # f\"v4l2-ctl -d {device} -c white_balance_automatic=0\",\n",
    "                    # f\"v4l2-ctl -d {device} -c white_balance_temperature=4675\",\n",
    "                    # f\"v4l2-ctl -d {device} -c brightness=128\",\n",
    "                    # f\"v4l2-ctl -d {device} -c contrast=128\",\n",
    "                    # f\"v4l2-ctl -d {device} -c saturation=128\",\n",
    "                    ]\n",
    "                }\n",
    "\n",
    "def configure_camera(devices, config_commands):\n",
    "    for device in devices:\n",
    "\n",
    "        print(f\"Configuring camera on {device}...\")\n",
    "\n",
    "        for command in config_commands[device]:\n",
    "            subprocess.run(command, shell=True, check=True)\n",
    "\n",
    "        print(\"Camera configuration complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Camera Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "# Configure and open cameras to check proper configs\n",
    "cap0 = cv2.VideoCapture(cam0_device, cv2.CAP_V4L2)\n",
    "cap1 = cv2.VideoCapture(cam1_device, cv2.CAP_V4L2)\n",
    "# configure_camera([cam0_device, cam1_device], config_commands) # Uncomment to use default configs\n",
    "\n",
    "if not cap0.isOpened() or not cap1.isOpened():\n",
    "    print(\"Error: One or both cameras could not be opened.\")\n",
    "    exit()\n",
    "\n",
    "cam0_focus_adjust = cam0_focus_value\n",
    "cam1_focus_adjust = cam1_focus_value\n",
    "# configure_wait_time = 2 # wait this many seconds to configure manual settings\n",
    "# configure_yet = False\n",
    "# start_time = time.time()\n",
    "while True:\n",
    "    # if time.time() - start_time > configure_wait_time and not configure_yet:\n",
    "    #     configure_camera([cam0_device, cam1_device], config_commands)\n",
    "    #     configure_yet = True\n",
    "    #     print(\"Configured manual camera settings!!!\")\n",
    "\n",
    "    # Read frames from both cameras\n",
    "    ret0, frame0 = cap0.read()\n",
    "    ret1, frame1 = cap1.read()\n",
    "\n",
    "    if not ret0 or not ret1:\n",
    "        print(\"Error: One or both frames could not be read.\")\n",
    "        break\n",
    "\n",
    "    # Display each camera feed in separate windows\n",
    "    cv2.putText(frame0, f\"Focus: {cam0_focus_adjust}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.putText(frame1, f\"Focus: {cam1_focus_adjust}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.imshow(\"Camera 0 (top)\", frame0)\n",
    "    cv2.imshow(\"Camera 1 (side)\", frame1)\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    if key == 27:  # ESC key to exit\n",
    "        break\n",
    "    elif key == ord('q'):  # Increase focus for Camera 0\n",
    "        cam0_focus_adjust = min(cam0_focus_adjust + 5, 250)\n",
    "        command = f\"v4l2-ctl -d {cam0_device} -c focus_absolute={cam0_focus_adjust}\"\n",
    "        subprocess.run(command, shell=True)\n",
    "        print(f\"Cam 0 focus set to: {cam0_focus_adjust}\")\n",
    "    elif key == ord('a'):  # Decrease focus for Camera 0\n",
    "        cam0_focus_adjust = max(cam0_focus_adjust - 5, 0)\n",
    "        command = f\"v4l2-ctl -d {cam0_device} -c focus_absolute={cam0_focus_adjust}\"\n",
    "        subprocess.run(command, shell=True)\n",
    "        print(f\"Cam 0 focus set to: {cam0_focus_adjust}\")\n",
    "    elif key == ord('w'): # Increase focus for Camera 1\n",
    "        cam1_focus_adjust = min(cam1_focus_adjust + 5, 250)\n",
    "        command = f\"v4l2-ctl -d {cam1_device} -c focus_absolute={cam1_focus_adjust}\"\n",
    "        subprocess.run(command, shell=True)\n",
    "        print(f\"Cam 1 focus set to: {cam1_focus_adjust}\")\n",
    "    elif key == ord('s'):\n",
    "        # Decrease focus for Camera 1\n",
    "        cam1_focus_adjust = max(cam1_focus_adjust - 5, 0)\n",
    "        command = f\"v4l2-ctl -d {cam1_device} -c focus_absolute={cam1_focus_adjust}\"\n",
    "        subprocess.run(command, shell=True)\n",
    "        print(f\"Cam 1 focus set to: {cam1_focus_adjust}\")\n",
    "\n",
    "# Release both cameras and close windows\n",
    "cap0.release()\n",
    "cap1.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect Intrinsic Calibration Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Make sure cameras are configures\n",
    "configure_camera([cam0_device, cam1_device], config_commands) # Uncomment to use default configs\n",
    "cap0 = cv2.VideoCapture(cam0_device, cv2.CAP_V4L2)\n",
    "cap1 = cv2.VideoCapture(cam1_device, cv2.CAP_V4L2)\n",
    "\n",
    "for i in range(2):\n",
    "    print(f\"Collecting instrinsic calibration images for camera {i}...\")\n",
    "    output_dir = f\"{calib_base_folder}/charuco_calib_images/cam{i}\"  # Directory to save images\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Initialize webcam\n",
    "    cap = cv2.VideoCapture(port_ids[i], cv2.CAP_V4L2)\n",
    "\n",
    "    # Check if camera opened successfully\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open camera.\")\n",
    "        exit()\n",
    "\n",
    "    print(\"Press SPACE to capture image, ESC to exit.\")\n",
    "\n",
    "    image_count = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Failed to capture image.\")\n",
    "            break\n",
    "\n",
    "        # Display the live feed\n",
    "        cv2.imshow(\"Camera Feed - Press SPACE to capture, ESC to exit\", frame)\n",
    "\n",
    "        # Keyboard input\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        # Save image on SPACE key press\n",
    "        if key == ord(' '):\n",
    "            # Construct image filename\n",
    "            image_path = os.path.join(output_dir, f\"img_{image_count:03d}.png\")\n",
    "            # Save the frame as PNG\n",
    "            cv2.imwrite(image_path, frame)\n",
    "            print(f\"Captured: {image_path}\")\n",
    "            image_count += 1\n",
    "\n",
    "        # Exit on ESC key press\n",
    "        elif key == 27:\n",
    "            print(\"Exiting...\")\n",
    "            break\n",
    "\n",
    "    # Release the camera and close windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect Stereo Calibration Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect images of calibration board in both cameras frames for stereo extrinsic calibration\n",
    "import cv2\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "output_dir = f\"{calib_base_folder}/stereo_calib_images\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Make sure cameras are configures\n",
    "configure_camera([cam0_device, cam1_device], config_commands) # Uncomment to use default configs\n",
    "cap0 = cv2.VideoCapture(port_ids[0], cv2.CAP_V4L2)\n",
    "cap1 = cv2.VideoCapture(port_ids[1], cv2.CAP_V4L2)\n",
    "\n",
    "while True:\n",
    "    # Read frames from both cameras\n",
    "    ret0, frame0 = cap0.read()\n",
    "    ret1, frame1 = cap1.read()\n",
    "\n",
    "    if not ret0 or not ret1:\n",
    "        print(\"Error: One or both frames could not be read.\")\n",
    "        break\n",
    "\n",
    "    # Display both camera feeds with timestamps\n",
    "    # timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")\n",
    "    # cv2.putText(frame1, f\"Cam1 - {timestamp}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    # cv2.putText(frame2, f\"Cam2 - {timestamp}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    # Combine and display both frames\n",
    "    combined = cv2.hconcat([frame0, frame1])\n",
    "    cv2.imshow(\"Camera 0 (top) + Camera 1 (side)\", combined)\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    if key == 27:  # ESC key to exit\n",
    "        break\n",
    "    elif key == ord(' '):  # Space key to capture images\n",
    "        # Save images with timestamp\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S_%f\")\n",
    "        img0_path = f\"{output_dir}/cam0_{frame_count}.png\"\n",
    "        img1_path = f\"{output_dir}/cam1_{frame_count}.png\"\n",
    "        cv2.imwrite(img0_path, frame0)\n",
    "        cv2.imwrite(img1_path, frame1)\n",
    "        print(f\"Captured images:\\n - {img0_path}\\n - {img1_path}\")\n",
    "        frame_count += 1\n",
    "\n",
    "# Release both cameras and close windows\n",
    "cap0.release()\n",
    "cap1.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect Camera-World Calibration Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect images for finding camera-world transform\n",
    "# Current approach is to use aruco marker to find camera 0 pose wrt to aruco marker\n",
    "# Then camera-camera transform can be used to find camera 1 to world transform\n",
    "\n",
    "# Make sure cameras are configured\n",
    "configure_camera([cam0_device], config_commands)\n",
    "cap = cv2.VideoCapture(port_ids[0], cv2.CAP_V4L2)\n",
    "\n",
    "output_dir = f\"{calib_base_folder}/extrinsic_calib_images/cam0\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "while True:\n",
    "    # Read frame from camera\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"Error: Frame could not be read.\")\n",
    "        break\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow(\"Camera Feed - Press SPACE to capture, ESC to exit\", frame)\n",
    "\n",
    "    # Keyboard input\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    # Save image on SPACE key press\n",
    "    if key == ord(' '):\n",
    "        # Construct image filename\n",
    "        image_path = os.path.join(output_dir, f\"img_aruco.png\")\n",
    "        # Save the frame as PNG\n",
    "        cv2.imwrite(image_path, frame)\n",
    "        print(f\"Captured: {image_path}\")\n",
    "\n",
    "    # Exit on ESC key press\n",
    "    elif key == 27:\n",
    "        print(\"Exiting...\")\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Camera Calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Intrinsics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute intrinsic, stereo extrinsic, and camera to world transforms\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2.aruco as aruco\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "def calibrate_intrinsics_charuco(glob_pattern, charuco_board, aruco_dict,\n",
    "                                 min_markers=20):\n",
    "    '''\n",
    "    Calibrates camera intrinsics using a ChArUco board.\n",
    "    '''\n",
    "    all_corners, all_ids, img_size = [], [], None\n",
    "\n",
    "    for fname in glob.glob(glob_pattern):\n",
    "        img = cv2.imread(fname)\n",
    "        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        if img_size is None:\n",
    "            img_size = img_gray.shape[::-1]\n",
    "\n",
    "        detector = aruco.CharucoDetector(charuco_board)\n",
    "        charuco_corners, charuco_ids, marker_corners, marker_ids = detector.detectBoard(img_gray)\n",
    "\n",
    "        all_corners.append(charuco_corners)\n",
    "        all_ids.append(charuco_ids)\n",
    "\n",
    "    # 3. Calibrate\n",
    "    ret, K, dist, rvecs, tvecs = aruco.calibrateCameraCharuco(\n",
    "        charucoCorners=all_corners,\n",
    "        charucoIds=all_ids,\n",
    "        board=charuco_board,\n",
    "        imageSize=img_size,\n",
    "        cameraMatrix=None,\n",
    "        distCoeffs=None\n",
    "    )\n",
    "    return ret, K, dist, rvecs, tvecs\n",
    "\n",
    "# Dict holding all camera calibration data\n",
    "camera_calib_data = {\n",
    "        \"cam0\": {\n",
    "            \"intrinsics\": {\n",
    "                \"K\": None,\n",
    "                \"d\": None\n",
    "            },\n",
    "            \"extrinsics\": { # this is camera to world transform\n",
    "                \"R\": None,\n",
    "                \"T\": None\n",
    "            }\n",
    "        },\n",
    "        \"cam1\": {\n",
    "            \"intrinsics\": {\n",
    "                \"K\": None,\n",
    "                \"d\": None\n",
    "            },\n",
    "            \"extrinsics\": {\n",
    "                \"R\": None,\n",
    "                \"T\": None\n",
    "            }\n",
    "        },\n",
    "        \"stereo_extrinsics\": { # Camera to camera transform (from cam0 to cam1)\n",
    "            \"R_1_0\": None,\n",
    "            \"T_1_0\": None,\n",
    "        },\n",
    "    }\n",
    "\n",
    "# Define ChArUco board used\n",
    "square_size = 0.006\n",
    "marker_length = 0.004\n",
    "board_size = (10, 10)\n",
    "aruco_dict = aruco.getPredefinedDictionary(aruco.DICT_4X4_50)\n",
    "charuco_board = aruco.CharucoBoard(\n",
    "    size=board_size,\n",
    "    squareLength=square_size, \n",
    "    markerLength=marker_length,\n",
    "    dictionary=aruco_dict\n",
    ")\n",
    "\n",
    "# Calibrate instrinsics\n",
    "for i in range(2):\n",
    "    intrinsic_calib_images_path = f\"{calib_base_folder}/charuco_calib_images/cam{i}/*.png\"\n",
    "    rms_error, K, d, _, _ = calibrate_intrinsics_charuco(\n",
    "        intrinsic_calib_images_path, charuco_board, aruco_dict\n",
    "    )\n",
    "    print(f\"Charuco intrinsics for camera {i} RMS error: {rms_error:.4f}\")\n",
    "    print(f\"Camera {i} intrinsic matrix:\\n{K}\")\n",
    "    print(f\"Camera {i} distortion coefficients:\\n{d}\")\n",
    "    camera_calib_data[f\"cam{i}\"][\"intrinsics\"][\"K\"] = K\n",
    "    camera_calib_data[f\"cam{i}\"][\"intrinsics\"][\"d\"] = d\n",
    "\n",
    "print(\"Intrinsic calibration complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Stereo Extrinsics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2.aruco as aruco\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "def detect_charuco_corners(image_path, board, detector):\n",
    "    \"\"\"Detects Charuco corners using OpenCV 4.11+ functions.\"\"\"\n",
    "    img = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect Aruco markers and Charuco corners\n",
    "    charuco_corners, charuco_ids, _, _ = detector.detectBoard(gray)\n",
    "\n",
    "    if charuco_ids is not None and len(charuco_ids) > 4:\n",
    "        return charuco_corners, charuco_ids\n",
    "    return None, None\n",
    "\n",
    "def calculate_relative_transform(R1, T1, R2, T2):\n",
    "    \"\"\"Calculate the relative rotation and translation between two cameras.\n",
    "    Returns R21 and T21, the rotation and translation of camera 2 in camera 1's frame.\"\"\"\n",
    "    R21 = np.dot(R2, R1.T)\n",
    "    T21 = T2 - np.dot(R21, T1)\n",
    "    return R21, T21\n",
    "\n",
    "def get_extrinsics(image_path, K, dist, board, detector):\n",
    "    \"\"\"Compute extrinsics for a single image.\"\"\"\n",
    "    charuco_corners, charuco_ids = detect_charuco_corners(image_path, board, detector)\n",
    "    if charuco_corners is not None:\n",
    "        obj_points = board.getChessboardCorners()[charuco_ids.flatten()]\n",
    "        ret, rvec, tvec = cv2.solvePnP(obj_points, charuco_corners, K, dist)\n",
    "        if ret:\n",
    "            R, _ = cv2.Rodrigues(rvec)\n",
    "            return R, tvec\n",
    "    return None, None\n",
    "\n",
    "# # Load intrinsic parameters\n",
    "# calib_data_file = \"../camera_calibration/05-08-25/camera_calib_data.pkl\"\n",
    "# with open(calib_data_file, 'rb') as f:\n",
    "#     calib_data = pickle.load(f)\n",
    "\n",
    "K0 = camera_calib_data[\"cam0\"][\"intrinsics\"][\"K\"]\n",
    "dist0 = camera_calib_data[\"cam0\"][\"intrinsics\"][\"d\"]\n",
    "K1 = camera_calib_data[\"cam1\"][\"intrinsics\"][\"K\"]\n",
    "dist1 = camera_calib_data[\"cam1\"][\"intrinsics\"][\"d\"]\n",
    "\n",
    "# Define ChArUco board used\n",
    "square_size = 0.006\n",
    "marker_length = 0.004\n",
    "board_size = (10, 10)\n",
    "aruco_dict = aruco.getPredefinedDictionary(aruco.DICT_4X4_50)\n",
    "charuco_board = aruco.CharucoBoard(\n",
    "    size=board_size,\n",
    "    squareLength=square_size, \n",
    "    markerLength=marker_length,\n",
    "    dictionary=aruco_dict\n",
    ")\n",
    "\n",
    "# Create the Aruco and Charuco detector objects (new in OpenCV 4.11+)\n",
    "aruco_detector = aruco.ArucoDetector(aruco_dict)\n",
    "charuco_detector = aruco.CharucoDetector(charuco_board)\n",
    "\n",
    "# Paths to synchronized images\n",
    "cam0_images = sorted(glob.glob(f\"{calib_base_folder}/stereo_calib_images/cam0_*.png\"))\n",
    "cam1_images = sorted(glob.glob(f\"{calib_base_folder}/stereo_calib_images/cam1_*.png\"))\n",
    "\n",
    "# Arrays to store transformations\n",
    "relative_rotations = []\n",
    "relative_translations = []\n",
    "\n",
    "for img0_path, img1_path in zip(cam0_images, cam1_images):\n",
    "    # Get extrinsics for both cameras using updated functions\n",
    "    R0, T0 = get_extrinsics(img0_path, K0, dist0, charuco_board, charuco_detector)\n",
    "    R1, T1 = get_extrinsics(img1_path, K1, dist1, charuco_board, charuco_detector)\n",
    "\n",
    "    if R0 is not None and R1 is not None:\n",
    "        # Calculate the relative transformation between cameras\n",
    "        R10, T10 = calculate_relative_transform(R0, T0, R1, T1)\n",
    "        relative_rotations.append(R10)\n",
    "        relative_translations.append(T10)\n",
    "\n",
    "# Average the transformations\n",
    "R_avg = sum(relative_rotations) / len(relative_rotations)\n",
    "T_avg = sum(relative_translations) / len(relative_translations)\n",
    "\n",
    "# Print the averaged relative transformation\n",
    "print(\"Transform from Camera 0 to Camera 1:\")\n",
    "print(\"Averaged Relative Rotation (R10):\\n\", R_avg)\n",
    "print(\"Averaged Relative Translation (T10):\\n\", T_avg)\n",
    "\n",
    "# Save the relative transformation\n",
    "camera_calib_data[\"stereo_extrinsics\"][\"R_1_0\"] = R_avg\n",
    "camera_calib_data[\"stereo_extrinsics\"][\"T_1_0\"] = T_avg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Camera-World Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[[295., 147.],\n",
      "        [307., 146.],\n",
      "        [308., 159.],\n",
      "        [296., 159.]]], dtype=float32),)\n",
      "Camera 0 to World Rotation:\n",
      "[[ 0.96241617  0.07780901  0.26019391]\n",
      " [ 0.002285    0.95572452 -0.29425401]\n",
      " [-0.27156931  0.28378936  0.91962694]]\n",
      "Camera 0 to World Translation:\n",
      "[[-0.00391395]\n",
      " [-0.03319903]\n",
      " [ 0.20169472]]\n",
      "Camera 1 to World Rotation:\n",
      "[[ 0.27576602 -0.25516868 -0.92672725]\n",
      " [-0.05900692  0.95778878 -0.28126257]\n",
      " [ 0.95939296  0.13223629  0.24905744]]\n",
      "Camera 1 to World Translation:\n",
      "[[-0.03173681]\n",
      " [-0.01782421]\n",
      " [ 0.22452266]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import cv2.aruco as aruco\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "def solve_pnp(marker_corners, marker_length, K, dist):\n",
    "    \"\"\"Solve PnP for a single Aruco marker.\"\"\"\n",
    "    half_length = marker_length / 2\n",
    "\n",
    "    # 3D points of the marker corners in the world coordinate system (origin at one corner)\n",
    "    obj_points = np.array([\n",
    "        [0, 0, 0],                  # Bottom-left (origin)\n",
    "        [marker_length, 0, 0],      # Bottom-right (X-axis)\n",
    "        [marker_length, marker_length, 0], # Top-right\n",
    "        [0, marker_length, 0]       # Top-left (Z-axis)\n",
    "    ], dtype=np.float32)\n",
    "\n",
    "    # Solve PnP to find rotation and translation\n",
    "    ret, rvec, tvec = cv2.solvePnP(obj_points, marker_corners, K, dist)\n",
    "    if ret:\n",
    "        R, _ = cv2.Rodrigues(rvec)\n",
    "        return R, tvec\n",
    "    return None, None\n",
    "\n",
    "def draw_axes(image, R, T, K, dist):\n",
    "    \"\"\"Draw the world frame origin and axes on the image.\"\"\"\n",
    "    axis_length = 0.05  # 5 cm\n",
    "\n",
    "    # Define the 3D points for the axes\n",
    "    axis_points = np.float32([\n",
    "        [0, 0, 0],              # Origin\n",
    "        [axis_length, 0, 0],    # X-axis (red)\n",
    "        [0, axis_length, 0],    # Y-axis (green)\n",
    "        [0, 0, axis_length]     # Z-axis (blue)\n",
    "    ]).reshape(-1, 3)\n",
    "\n",
    "    # Project the 3D axis points onto the image plane\n",
    "    img_points, _ = cv2.projectPoints(axis_points, cv2.Rodrigues(R)[0], T, K, dist)\n",
    "\n",
    "    # Draw the origin point\n",
    "    origin = tuple(img_points[0].ravel().astype(int))\n",
    "    cv2.circle(image, origin, 5, (0, 0, 255), -1)\n",
    "\n",
    "    # Draw the X, Y, Z axes\n",
    "    cv2.line(image, origin, tuple(img_points[1].ravel().astype(int)), (0, 0, 255), 3)  # X-axis (red)\n",
    "    cv2.line(image, origin, tuple(img_points[2].ravel().astype(int)), (0, 255, 0), 3)  # Y-axis (green)\n",
    "    cv2.line(image, origin, tuple(img_points[3].ravel().astype(int)), (255, 0, 0), 3)  # Z-axis (blue)\n",
    "\n",
    "    # Annotate the axes\n",
    "    cv2.putText(image, \"X\", tuple(img_points[1].ravel().astype(int)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "    cv2.putText(image, \"Y\", tuple(img_points[2].ravel().astype(int)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.putText(image, \"Z\", tuple(img_points[3].ravel().astype(int)), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "\n",
    "# Load intrinsic calibration data\n",
    "# # Load intrinsic parameters\n",
    "calib_data_file = f\"{calib_base_folder}/camera_calib_data.pkl\"\n",
    "with open(calib_data_file, 'rb') as f:\n",
    "    camera_calib_data = pickle.load(f)\n",
    "\n",
    "K = camera_calib_data[\"cam0\"][\"intrinsics\"][\"K\"]\n",
    "dist = camera_calib_data[\"cam0\"][\"intrinsics\"][\"d\"]\n",
    "\n",
    "\n",
    "# Aruco marker parameters\n",
    "aruco_dict = aruco.getPredefinedDictionary(aruco.DICT_4X4_50)\n",
    "marker_length = 0.004  # Length of the marker side in meters\n",
    "\n",
    "# Initialize the Aruco detector\n",
    "detector = aruco.ArucoDetector(aruco_dict)\n",
    "\n",
    "# Load image\n",
    "img = cv2.imread(f\"{calib_base_folder}/extrinsic_calib_images/cam0/img_aruco.png\")\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detect the Aruco marker\n",
    "corners, ids, _ = detector.detectMarkers(img_gray)\n",
    "print(corners)\n",
    "\n",
    "if ids is not None:\n",
    "    R_0_w, T_0_w = solve_pnp(corners[0], marker_length, K, dist)\n",
    "    if R_0_w is not None:\n",
    "        print(f\"Camera 0 to World Rotation:\\n{R_0_w}\")\n",
    "        print(f\"Camera 0 to World Translation:\\n{T_0_w}\")\n",
    "\n",
    "        # Draw the marker and the world frame\n",
    "        aruco.drawDetectedMarkers(img, corners, ids)\n",
    "        draw_axes(img, R_0_w, T_0_w, K, dist)\n",
    "\n",
    "# Compute Camera 1 to world transform using stereo extrinsics\n",
    "R_1_0 = camera_calib_data[\"stereo_extrinsics\"][\"R_1_0\"]\n",
    "T_1_0 = camera_calib_data[\"stereo_extrinsics\"][\"T_1_0\"]\n",
    "R_1_w = np.dot(R_1_0, R_0_w)\n",
    "T_1_w = np.dot(R_1_0, T_0_w) + T_1_0\n",
    "print(f\"Camera 1 to World Rotation:\\n{R_1_w}\")\n",
    "print(f\"Camera 1 to World Translation:\\n{T_1_w}\")\n",
    "\n",
    "# save all calibration data\n",
    "camera_calib_data[\"cam0\"][\"extrinsics\"][\"R\"] = R_0_w\n",
    "camera_calib_data[\"cam0\"][\"extrinsics\"][\"T\"] = T_0_w\n",
    "camera_calib_data[\"cam1\"][\"extrinsics\"][\"R\"] = R_1_w\n",
    "camera_calib_data[\"cam1\"][\"extrinsics\"][\"T\"] = T_1_w\n",
    "\n",
    "with open(f\"{calib_base_folder}/camera_calib_data.pkl\", \"wb\") as f:\n",
    "    pickle.dump(camera_calib_data, f)\n",
    "\n",
    "cv2.imshow(\"Camera 0 - Aruco Marker with World Frame\", img)\n",
    "cv2.imwrite(f\"{calib_base_folder}/extrinsic_calib_images/cam0/img_aruco_with_axes.png\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify camera to world transform by projecting axes onto image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import cv2.aruco as aruco\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Load calibration data\n",
    "with open(f\"{calib_base_folder}/camera_calib_data.pkl\", \"rb\") as f:\n",
    "    camera_calib_data = pickle.load(f)\n",
    "\n",
    "# Load intrinsic and extrinsic parameters for both cameras\n",
    "K0 = camera_calib_data[\"cam0\"][\"intrinsics\"][\"K\"]\n",
    "dist0 = camera_calib_data[\"cam0\"][\"intrinsics\"][\"d\"]\n",
    "R_0_w = camera_calib_data[\"cam0\"][\"extrinsics\"][\"R\"]\n",
    "T_0_w = camera_calib_data[\"cam0\"][\"extrinsics\"][\"T\"]\n",
    "\n",
    "K1 = camera_calib_data[\"cam1\"][\"intrinsics\"][\"K\"]\n",
    "dist1 = camera_calib_data[\"cam1\"][\"intrinsics\"][\"d\"]\n",
    "R_1_w = camera_calib_data[\"cam1\"][\"extrinsics\"][\"R\"]\n",
    "T_1_w = camera_calib_data[\"cam1\"][\"extrinsics\"][\"T\"]\n",
    "\n",
    "# Load images for verification\n",
    "img0 = cv2.imread(f\"../tip_pose_images/cam0_0.png\")\n",
    "img1 = cv2.imread(f\"../tip_pose_images/cam1_0.png\")\n",
    "\n",
    "# Draw world frame axes on Camera 0 image\n",
    "draw_axes(img0, R_0_w, T_0_w, K0, dist0)\n",
    "cv2.imshow(\"Camera 0 - World Frame Projection\", img0)\n",
    "\n",
    "# Draw world frame axes on Camera 1 image\n",
    "draw_axes(img1, R_1_w, T_1_w, K1, dist1)\n",
    "cv2.imshow(\"Camera 1 - World Frame Projection\", img1)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
