{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import cv2.aruco as aruco\n",
    "import os\n",
    "import numpy as np\n",
    "import subprocess\n",
    "\n",
    "calib_id = \"08-05-25\"\n",
    "calib_base_folder = f\"/home/arclab/catkin_ws/src/Catheter-Perception/camera_calibration/{calib_id}\"\n",
    "# calib_base_folder = f\"C:\\\\Users\\\\jlim\\\\Documents\\\\GitHub\\\\Catheter-Perception\\\\camera_calibration\\\\{calib_id}\"\n",
    "# Camera 0 refers to top camera, Camera 1 refers to bottom camera\n",
    "# Ensure camera port ids are correct\n",
    "# port_ids = [0, 2]\n",
    "cam0_device = \"/dev/cam0\"\n",
    "cam1_device = \"/dev/cam1\"\n",
    "cam2_device = \"/dev/cam2\"\n",
    "devices = [f\"/dev/cam{i}\" for i in range(3)]\n",
    "cap_frame_width = 1280\n",
    "cap_frame_height = 720\n",
    "\n",
    "# Ensure proper camera configurations\n",
    "focus_values = [45, 70, 80]  # Default focus values for cam0, cam1, cam2\n",
    "config_commands = {cam0_device: [\n",
    "                    f\"v4l2-ctl -d {cam0_device} -c focus_automatic_continuous=0\",\n",
    "                    f\"v4l2-ctl -d {cam0_device} -c auto_exposure=3\",\n",
    "                    f\"v4l2-ctl -d {cam0_device} -c focus_absolute={focus_values[0]}\",\n",
    "                    # f\"v4l2-ctl -d {device} -c exposure_time_absolute=333\",\n",
    "                    # f\"v4l2-ctl -d {device} -c gain=0\",\n",
    "                    # f\"v4l2-ctl -d {device} -c white_balance_automatic=0\",\n",
    "                    # f\"v4l2-ctl -d {device} -c white_balance_temperature=4675\",\n",
    "                    # f\"v4l2-ctl -d {device} -c brightness=128\",\n",
    "                    # f\"v4l2-ctl -d {device} -c contrast=128\",\n",
    "                    # f\"v4l2-ctl -d {device} -c saturation=128\",\n",
    "                    ],\n",
    "                cam1_device: [\n",
    "                    f\"v4l2-ctl -d {cam1_device} -c focus_automatic_continuous=0\",\n",
    "                    f\"v4l2-ctl -d {cam1_device} -c auto_exposure=3\",\n",
    "                    f\"v4l2-ctl -d {cam1_device} -c focus_absolute={focus_values[1]}\",\n",
    "                    # f\"v4l2-ctl -d {device} -c exposure_time_absolute=333\",\n",
    "                    # f\"v4l2-ctl -d {device} -c gain=0\",\n",
    "                    # f\"v4l2-ctl -d {device} -c white_balance_automatic=0\",\n",
    "                    # f\"v4l2-ctl -d {device} -c white_balance_temperature=4675\",\n",
    "                    # f\"v4l2-ctl -d {device} -c brightness=128\",\n",
    "                    # f\"v4l2-ctl -d {device} -c contrast=128\",\n",
    "                    # f\"v4l2-ctl -d {device} -c saturation=128\",\n",
    "                    ],\n",
    "                cam2_device: [\n",
    "                    f\"v4l2-ctl -d {cam2_device} -c focus_automatic_continuous=0\",\n",
    "                    f\"v4l2-ctl -d {cam2_device} -c auto_exposure=3\",\n",
    "                    f\"v4l2-ctl -d {cam2_device} -c focus_absolute={focus_values[2]}\",\n",
    "                    # f\"v4l2-ctl -d {device} -c exposure_time_absolute=333\",\n",
    "                    # f\"v4l2-ctl -d {device} -c gain=0\",\n",
    "                    # f\"v4l2-ctl -d {device} -c white_balance_automatic=0\",\n",
    "                    # f\"v4l2-ctl -d {device} -c white_balance_temperature=4675\",\n",
    "                    # f\"v4l2-ctl -d {device} -c brightness=128\",\n",
    "                    # f\"v4l2-ctl -d {device} -c contrast=128\",\n",
    "                    # f\"v4l2-ctl -d {device} -c saturation=128\",\n",
    "                    ],\n",
    "                }\n",
    "\n",
    "def configure_camera(devices, config_commands):\n",
    "    for device in devices:\n",
    "\n",
    "        print(f\"Configuring camera on {device}...\")\n",
    "\n",
    "        for command in config_commands[device]:\n",
    "            subprocess.run(command, shell=True, check=True)\n",
    "\n",
    "        print(\"Camera configuration complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Camera Focus Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "# Configure and open cameras to check proper configs\n",
    "d=2\n",
    "cap = cv2.VideoCapture(devices[d], cv2.CAP_V4L2)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, cap_frame_width)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, cap_frame_height)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: One or both cameras could not be opened.\")\n",
    "    exit()\n",
    "\n",
    "focus_adjust = focus_values[d]\n",
    "configure_wait_time = 2 # wait this many seconds to configure manual settings\n",
    "configure_yet = False\n",
    "start_time = time.time()\n",
    "while True:\n",
    "    if time.time() - start_time > configure_wait_time and not configure_yet:\n",
    "        configure_camera([devices[d]], config_commands)\n",
    "        configure_yet = True\n",
    "        print(\"Configured manual camera settings!!!\")\n",
    "\n",
    "    # Read frames from both cameras\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"Error: One or both frames could not be read.\")\n",
    "        break\n",
    "    cv2.putText(frame, f\"Focus: {focus_adjust}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.imshow(f\"Camera {d}\", frame)\n",
    "\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    if key == 27:  # ESC key to exit\n",
    "        break\n",
    "    elif key == ord('q'):  # Increase focus for Camera 0\n",
    "        focus_adjust = min(focus_adjust + 5, 250)\n",
    "        command = f\"v4l2-ctl -d {devices[d]} -c focus_absolute={focus_adjust}\"\n",
    "        subprocess.run(command, shell=True)\n",
    "        print(f\"Cam {d} focus set to: {focus_adjust}\")\n",
    "    elif key == ord('a'):  # Decrease focus for Camera 0\n",
    "        focus_adjust = max(focus_adjust - 5, 0)\n",
    "        command = f\"v4l2-ctl -d {devices[d]} -c focus_absolute={focus_adjust}\"\n",
    "        subprocess.run(command, shell=True)\n",
    "\n",
    "# Release both cameras and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Camera configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "# Configure and open cameras to check proper configs\n",
    "caps = []\n",
    "for device in devices:\n",
    "    cap = cv2.VideoCapture(device, cv2.CAP_V4L2)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, cap_frame_width)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, cap_frame_height)\n",
    "    caps.append(cap)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Camera {device} could not be opened.\")\n",
    "        exit()\n",
    "\n",
    "configure_wait_time = 2 # wait this many seconds to configure manual settings\n",
    "configure_yet = False\n",
    "start_time = time.time()\n",
    "while True:\n",
    "    if time.time() - start_time > configure_wait_time and not configure_yet:\n",
    "        configure_camera(devices, config_commands)\n",
    "        configure_yet = True\n",
    "        print(\"Configured manual camera settings!!!\")\n",
    "\n",
    "    # Read frames from both cameras\n",
    "    for i, cap in enumerate(caps):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Frame could not be read from camera.\")\n",
    "            exit()\n",
    "        frame = cv2.resize(frame, (cap_frame_width//2, cap_frame_height//2))\n",
    "        cv2.imshow(f\"Camera {i} (Device: {devices[i]})\", frame)\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    if key == 27:  # ESC key to exit\n",
    "        break\n",
    "    elif key == ord('q'):  # Increase focus for Camera 0\n",
    "        cam0 = min(cam0 + 5, 250)\n",
    "        command = f\"v4l2-ctl -d {cam0_device} -c focus_absolute={cam0_focus_adjust}\"\n",
    "        subprocess.run(command, shell=True)\n",
    "        print(f\"Cam 0 focus set to: {cam0_focus_adjust}\")\n",
    "    elif key == ord('a'):  # Decrease focus for Camera 0\n",
    "        cam0_focus_adjust = max(cam0_focus_adjust - 5, 0)\n",
    "        command = f\"v4l2-ctl -d {cam0_device} -c focus_absolute={cam0_focus_adjust}\"\n",
    "        subprocess.run(command, shell=True)\n",
    "        print(f\"Cam 0 focus set to: {cam0_focus_adjust}\")\n",
    "    elif key == ord('w'): # Increase focus for Camera 1\n",
    "        cam1_focus_adjust = min(cam1_focus_adjust + 5, 250)\n",
    "        command = f\"v4l2-ctl -d {cam1_device} -c focus_absolute={cam1_focus_adjust}\"\n",
    "        subprocess.run(command, shell=True)\n",
    "        print(f\"Cam 1 focus set to: {cam1_focus_adjust}\")\n",
    "    elif key == ord('s'):\n",
    "        # Decrease focus for Camera 1\n",
    "        cam1_focus_adjust = max(cam1_focus_adjust - 5, 0)\n",
    "        command = f\"v4l2-ctl -d {cam1_device} -c focus_absolute={cam1_focus_adjust}\"\n",
    "        subprocess.run(command, shell=True)\n",
    "        print(f\"Cam 1 focus set to: {cam1_focus_adjust}\")\n",
    "\n",
    "# Release both cameras and close windows\n",
    "for cap in caps:\n",
    "    cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "roi_boxes = []\n",
    "for d in range(len(devices)):\n",
    "    cap = cv2.VideoCapture(devices[d], cv2.CAP_V4L2)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, cap_frame_width)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, cap_frame_height)\n",
    "\n",
    "    print(\"Press SPACE to freeze frame and select ROI.\")\n",
    "    print(\"Draw the box, then press ENTER to confirm or ESC to cancel.\")\n",
    "\n",
    "    roi_box = None\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame.\")\n",
    "            break\n",
    "\n",
    "        cv2.imshow(\"Live Feed\", frame)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        if key == 32:  # SPACE to pause and select ROI\n",
    "            cv2.imshow(\"Select ROI\", frame)\n",
    "            roi_box = cv2.selectROI(\"Select ROI\", frame, showCrosshair=True, fromCenter=False)\n",
    "            cv2.destroyWindow(\"Select ROI\")\n",
    "\n",
    "            if roi_box != (0, 0, 0, 0):\n",
    "                x, y, w, h = roi_box\n",
    "                cropped = frame[y:y+h, x:x+w]\n",
    "                cv2.imshow(\"Cropped ROI\", cropped)\n",
    "                print(f\"ROI Coordinates: x={x}, y={y}, w={w}, h={h}\")\n",
    "            else:\n",
    "                print(\"No ROI selected.\")\n",
    "\n",
    "        elif key == 27:  # ESC to exit\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    print(f\"Final ROI for Camera {d}: {roi_box}\")\n",
    "    roi_boxes.append(roi_box)\n",
    "\n",
    "# Save the ROI coordinates to a file\n",
    "roi_file_path = os.path.join(calib_base_folder, f\"roi_cam{d}.txt\")\n",
    "with open(roi_file_path, 'w') as f:\n",
    "    for box in roi_boxes:\n",
    "        f.write(f\"{box[0]} {box[1]} {box[2]} {box[3]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect Intrinsic Calibration Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "devices = [f\"/dev/cam{i}\" for i in [2]]\n",
    "\n",
    "for i, device in enumerate(devices):\n",
    "    print(f\"Collecting instrinsic calibration images for camera {i}...\")\n",
    "    output_dir = f\"{calib_base_folder}/intrinsic_calib_images/cam{i}\"  # Directory to save images\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Initialize webcam\n",
    "    cap = cv2.VideoCapture(device, cv2.CAP_V4L2)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, cap_frame_width)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, cap_frame_height)\n",
    "\n",
    "    # Check if camera opened successfully\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open camera.\")\n",
    "        exit()\n",
    "\n",
    "    print(\"Press SPACE to capture image, ESC to exit.\")\n",
    "\n",
    "    image_count = 0\n",
    "    configure_wait_time = 2 # wait this many seconds to configure manual settings\n",
    "    configure_yet = False\n",
    "    start_time = time.time()\n",
    "    while True:\n",
    "        if time.time() - start_time > configure_wait_time and not configure_yet:\n",
    "            configure_camera([device], config_commands)\n",
    "            configure_yet = True\n",
    "            print(\"Configured manual camera settings!!!\")\n",
    "        \n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Failed to capture image.\")\n",
    "            break\n",
    "\n",
    "        # Display the live feed\n",
    "        cv2.imshow(\"Camera Feed - Press SPACE to capture, ESC to exit\", frame)\n",
    "\n",
    "        # Keyboard input\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        # Save image on SPACE key press\n",
    "        if key == ord(' '):\n",
    "            # Construct image filename\n",
    "            image_path = os.path.join(output_dir, f\"img_{image_count:03d}.png\")\n",
    "            # Save the frame as PNG\n",
    "            cv2.imwrite(image_path, frame)\n",
    "            print(f\"Captured: {image_path}\")\n",
    "            image_count += 1\n",
    "\n",
    "        # Exit on ESC key press\n",
    "        elif key == 27:\n",
    "            print(\"Exiting...\")\n",
    "            break\n",
    "\n",
    "    # Release the camera and close windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect Stereo Calibration Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect images of calibration board in both cameras frames for stereo extrinsic calibration\n",
    "import cv2\n",
    "import datetime\n",
    "import os\n",
    "import time\n",
    "\n",
    "device_ids = [0, 1]\n",
    "cur_devices = [f\"/dev/cam{i}\" for i in device_ids]\n",
    "output_dir = f\"{calib_base_folder}/stereo_calib_images\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "caps = []\n",
    "for device in cur_devices:\n",
    "    cap = cv2.VideoCapture(device, cv2.CAP_V4L2)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Camera {device} could not be opened.\")\n",
    "        exit()\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, cap_frame_width)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, cap_frame_height)\n",
    "    caps.append(cap)\n",
    "\n",
    "configure_wait_time = 2 # wait this many seconds to configure manual settings\n",
    "configure_yet = False\n",
    "start_time = time.time()\n",
    "frame_count = 0\n",
    "while True:\n",
    "    if time.time() - start_time > configure_wait_time and not configure_yet:\n",
    "        configure_camera(cur_devices, config_commands)\n",
    "        configure_yet = True\n",
    "        print(\"Configured manual camera settings!!!\")\n",
    "\n",
    "    # Read frames from both cameras\n",
    "    frames = []\n",
    "    for cap in caps:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Frame could not be read from camera.\")\n",
    "            exit()\n",
    "        # resize for better display\n",
    "        frame = cv2.resize(frame, (640, 480))\n",
    "        frames.append(frame)\n",
    "\n",
    "    # Combine and display both frames\n",
    "    combined = cv2.hconcat(frames)\n",
    "    cv2.imshow(f\"Camera {device_ids[0]} + Camera {device_ids[1]}\", combined)\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    if key == 27:  # ESC key to exit\n",
    "        break\n",
    "    elif key == ord(' '):  # Space key to capture images\n",
    "        # Save images with timestamp\n",
    "        for i, d in enumerate(device_ids):\n",
    "            img_path = f\"{output_dir}/cam{d}_{frame_count}.png\"\n",
    "            cv2.imwrite(img_path, frames[i])\n",
    "            print(f\"Captured images:\\n - {img_path}\\n\")\n",
    "        frame_count += 1\n",
    "\n",
    "# Release both cameras and close windows\n",
    "for cap in caps:\n",
    "    cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect Test Calib images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuring camera on /dev/cam0...\n",
      "Camera configuration complete!\n",
      "Configuring camera on /dev/cam1...\n",
      "Camera configuration complete!\n",
      "Configuring camera on /dev/cam2...\n",
      "Camera configuration complete!\n",
      "Configured manual camera settings!!!\n",
      "Captured images:\n",
      " - /home/arclab/catkin_ws/src/Catheter-Perception/camera_calibration/08-05-25/test_calib_images/cam0_0.png\n",
      "\n",
      "Captured images:\n",
      " - /home/arclab/catkin_ws/src/Catheter-Perception/camera_calibration/08-05-25/test_calib_images/cam1_0.png\n",
      "\n",
      "Captured images:\n",
      " - /home/arclab/catkin_ws/src/Catheter-Perception/camera_calibration/08-05-25/test_calib_images/cam2_0.png\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Collect images of calibration board in both cameras frames for stereo extrinsic calibration\n",
    "import cv2\n",
    "import datetime\n",
    "import os\n",
    "import time\n",
    "\n",
    "device_ids = [0, 1, 2]\n",
    "cur_devices = [f\"/dev/cam{i}\" for i in device_ids]\n",
    "output_dir = f\"{calib_base_folder}/test_calib_images\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "caps = []\n",
    "for device in cur_devices:\n",
    "    cap = cv2.VideoCapture(device, cv2.CAP_V4L2)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Camera {device} could not be opened.\")\n",
    "        exit()\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, cap_frame_width)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, cap_frame_height)\n",
    "    caps.append(cap)\n",
    "\n",
    "configure_wait_time = 2 # wait this many seconds to configure manual settings\n",
    "configure_yet = False\n",
    "start_time = time.time()\n",
    "frame_count = 0\n",
    "while True:\n",
    "    if time.time() - start_time > configure_wait_time and not configure_yet:\n",
    "        configure_camera(cur_devices, config_commands)\n",
    "        configure_yet = True\n",
    "        print(\"Configured manual camera settings!!!\")\n",
    "\n",
    "    # Read frames from both cameras\n",
    "    frames = []\n",
    "    for i, cap in enumerate(caps):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Frame could not be read from camera.\")\n",
    "            exit()\n",
    "        # resize for better display\n",
    "        frame_display = cv2.resize(frame, (640, 480))\n",
    "        frames.append(frame)\n",
    "        cv2.imshow(f\"Camera {device_ids[i]}\", frame_display)\n",
    "\n",
    "    # # Combine and display both frames\n",
    "    # combined = cv2.hconcat(frames)\n",
    "    # cv2.imshow(f\"Camera {device_ids[0]} + Camera {device_ids[1]}\", combined)\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    if key == 27:  # ESC key to exit\n",
    "        break\n",
    "    elif key == ord(' '):  # Space key to capture images\n",
    "        # Save images with timestamp\n",
    "        for i, d in enumerate(device_ids):\n",
    "            img_path = f\"{output_dir}/cam{d}_{frame_count}.png\"\n",
    "            cv2.imwrite(img_path, frames[i])\n",
    "            print(f\"Captured images:\\n - {img_path}\\n\")\n",
    "        frame_count += 1\n",
    "\n",
    "# Release both cameras and close windows\n",
    "for cap in caps:\n",
    "    cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect Camera-World Calibration Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect images for finding camera-world transform\n",
    "# Current approach is to use aruco marker to find camera 0 pose wrt to aruco marker\n",
    "# Then camera-camera transform can be used to find camera 1 to world transform\n",
    "import time\n",
    "\n",
    "# Make sure cameras are configured\n",
    "# Open cameras with higher resolution\n",
    "cap0 = cv2.VideoCapture(cam0_device, cv2.CAP_V4L2)\n",
    "cap1 = cv2.VideoCapture(cam1_device, cv2.CAP_V4L2)\n",
    "cap0.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "cap0.set(cv2.CAP_PROP_FRAME_HEIGHT, 920)\n",
    "cap1.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "cap1.set(cv2.CAP_PROP_FRAME_HEIGHT, 920)\n",
    "\n",
    "if not cap0.isOpened() or not cap1.isOpened():\n",
    "    print(\"Error: One or both cameras could not be opened.\")\n",
    "    exit()\n",
    "\n",
    "output_dir = f\"{calib_base_folder}/extrinsic_calib_images\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "configure_wait_time = 2 # wait this many seconds to configure manual settings\n",
    "configure_yet = False\n",
    "start_time = time.time()\n",
    "frame_count = 0\n",
    "while True:\n",
    "\n",
    "    if time.time() - start_time > configure_wait_time and not configure_yet:\n",
    "        configure_camera([cam0_device, cam1_device], config_commands)\n",
    "        configure_yet = True\n",
    "        print(\"Configured manual camera settings!!!\")\n",
    "\n",
    "    # Read frame from camera\n",
    "    ret0, frame0 = cap0.read()\n",
    "    ret1, frame1 = cap1.read()\n",
    "\n",
    "    if not ret0 or not ret1:\n",
    "        print(\"Error: Frame could not be read.\")\n",
    "        break\n",
    "\n",
    "    # Combine and display both frames\n",
    "    combined = cv2.hconcat([frame0, frame1])\n",
    "    cv2.imshow(\"Camera 0 (top) + Camera 1 (side)\", combined)\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    if key == 27:  # ESC key to exit\n",
    "        break\n",
    "    elif key == ord(' '):  # Space key to capture images\n",
    "        # Save images with timestamp\n",
    "        img0_path = f\"{output_dir}/cam0_{frame_count}.png\"\n",
    "        img1_path = f\"{output_dir}/cam1_{frame_count}.png\"\n",
    "        cv2.imwrite(img0_path, frame0)\n",
    "        cv2.imwrite(img1_path, frame1)\n",
    "        print(f\"Captured images:\\n - {img0_path}\\n - {img1_path}\")\n",
    "        frame_count += 1\n",
    "\n",
    "# Release both cameras and close windows\n",
    "cap0.release()\n",
    "cap1.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect camera 0 to world calibration image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting world transform calibration images for camera 0...\n",
      "Press SPACE to capture image, ESC to exit.\n",
      "Configuring camera on /dev/cam0...\n",
      "Camera configuration complete!\n",
      "Configured manual camera settings!!!\n",
      "Captured: /home/arclab/catkin_ws/src/Catheter-Perception/camera_calibration/08-05-25/cam0_world_transform/img_000.png\n",
      "Exiting...\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "devices = [f\"/dev/cam{i}\" for i in [0]]\n",
    "\n",
    "for i, device in enumerate(devices):\n",
    "    print(f\"Collecting world transform calibration images for camera {i}...\")\n",
    "    output_dir = f\"{calib_base_folder}/cam{i}_world_transform\"  # Directory to save images\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Initialize webcam\n",
    "    cap = cv2.VideoCapture(device, cv2.CAP_V4L2)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, cap_frame_width)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, cap_frame_height)\n",
    "\n",
    "    # Check if camera opened successfully\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open camera.\")\n",
    "        exit()\n",
    "\n",
    "    print(\"Press SPACE to capture image, ESC to exit.\")\n",
    "\n",
    "    image_count = 0\n",
    "    configure_wait_time = 2 # wait this many seconds to configure manual settings\n",
    "    configure_yet = False\n",
    "    start_time = time.time()\n",
    "    while True:\n",
    "        if time.time() - start_time > configure_wait_time and not configure_yet:\n",
    "            configure_camera([device], config_commands)\n",
    "            configure_yet = True\n",
    "            print(\"Configured manual camera settings!!!\")\n",
    "        \n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Failed to capture image.\")\n",
    "            break\n",
    "\n",
    "        # Display the live feed\n",
    "        cv2.imshow(\"Camera Feed - Press SPACE to capture, ESC to exit\", frame)\n",
    "\n",
    "        # Keyboard input\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        # Save image on SPACE key press\n",
    "        if key == ord(' '):\n",
    "            # Construct image filename\n",
    "            image_path = os.path.join(output_dir, f\"img_{image_count:03d}.png\")\n",
    "            # Save the frame as PNG\n",
    "            cv2.imwrite(image_path, frame)\n",
    "            print(f\"Captured: {image_path}\")\n",
    "            image_count += 1\n",
    "\n",
    "        # Exit on ESC key press\n",
    "        elif key == 27:\n",
    "            print(\"Exiting...\")\n",
    "            break\n",
    "\n",
    "    # Release the camera and close windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load yaml matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cam0': {'intrinsics': {'K': array([[939.00659834,   0.        , 610.34435618],\n",
      "       [  0.        , 938.71208314, 380.19234786],\n",
      "       [  0.        ,   0.        ,   1.        ]]), 'd': array([ 0.02409601, -0.11651624,  0.00295776, -0.00425454])}, 'extrinsics': {'R': None, 'T': None}}, 'cam1': {'intrinsics': {'K': array([[946.71215549,   0.        , 635.97087467],\n",
      "       [  0.        , 947.54229082, 378.04191205],\n",
      "       [  0.        ,   0.        ,   1.        ]]), 'd': array([ 0.03397451, -0.09771331,  0.00017749, -0.00423783])}, 'extrinsics': {'R': None, 'T': None}}, 'stereo_extrinsics': {'R_1_0': array([[-0.0133914 ,  0.99946859,  0.02971885],\n",
      "       [ 0.0304311 ,  0.03011512, -0.99908309],\n",
      "       [-0.99944716, -0.01247474, -0.03081821]]), 'T_1_0': array([[-0.0107076 ],\n",
      "       [ 0.14082601],\n",
      "       [ 0.13979356]]), 'R_2_1': array([[-0.02680169,  0.04737187, -0.99851769],\n",
      "       [ 0.02715598,  0.99854238,  0.04664413],\n",
      "       [ 0.99927185, -0.02586558, -0.02804905]]), 'T_2_1': array([[0.13355559],\n",
      "       [0.00672306],\n",
      "       [0.16317674]])}, 'cam2': {'intrinsics': {'K': array([[948.77457332,   0.        , 632.33643371],\n",
      "       [  0.        , 950.22636982, 364.02619265],\n",
      "       [  0.        ,   0.        ,   1.        ]]), 'd': array([ 0.04326954, -0.12884495,  0.00301781,  0.00080879])}, 'extrinsics': {'R': None, 'T': None}}}\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "# Dict holding all camera calibration data\n",
    "camera_calib_data = {\n",
    "        \"cam0\": {\n",
    "            \"intrinsics\": {\n",
    "                \"K\": None,\n",
    "                \"d\": None\n",
    "            },\n",
    "            \"extrinsics\": { # this is camera to world transform\n",
    "                \"R\": None,\n",
    "                \"T\": None\n",
    "            }\n",
    "        },\n",
    "        \"cam1\": {\n",
    "            \"intrinsics\": {\n",
    "                \"K\": None,\n",
    "                \"d\": None\n",
    "            },\n",
    "            \"extrinsics\": {\n",
    "                \"R\": None,\n",
    "                \"T\": None\n",
    "            }\n",
    "        },\n",
    "        \"stereo_extrinsics\": { # Camera to camera transform (from cam0 to cam1)\n",
    "            \"R_1_0\": None,\n",
    "            \"T_1_0\": None,\n",
    "            \"R_2_1\": None,\n",
    "            \"T_2_1\": None\n",
    "        }, \n",
    "        \"cam2\": {\n",
    "            \"intrinsics\": {\n",
    "                \"K\": None,\n",
    "                \"d\": None\n",
    "            },\n",
    "            \"extrinsics\": {\n",
    "                \"R\": None,\n",
    "                \"T\": None\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "def load_kalibr_intrinsics(yaml_data, cam_key):\n",
    "\n",
    "    cam_data = data[cam_key]\n",
    "    fx, fy, cx, cy = cam_data['intrinsics']\n",
    "    K = np.array([[fx, 0, cx],\n",
    "                  [0, fy, cy],\n",
    "                  [0,  0,  1]])\n",
    "    dist = np.array(cam_data['distortion_coeffs'])\n",
    "    return K, dist\n",
    "\n",
    "def load_kalibr_extrinsics(yaml_data, cam_key):\n",
    "    \"\"\"\n",
    "    Load extrinsics from kalibr yaml data.\n",
    "    Returns rotation matrix R and translation vector T.\n",
    "    \"\"\"\n",
    "    cam_data = yaml_data[cam_key]\n",
    "    matrix = np.array(cam_data['T_cn_cnm1'])\n",
    "    R = matrix[:3, :3]\n",
    "    T = matrix[:3, 3].reshape(-1, 1)\n",
    "    return R, T\n",
    "\n",
    "# Usage\n",
    "yaml_path = \"/home/arclab/catkin_ws/src/kalibr/08-05-25_T1-camchain.yaml\"\n",
    "with open(yaml_path, 'r') as f:\n",
    "    data = yaml.safe_load(f)\n",
    "\n",
    "for i, cam_key in enumerate(['cam0', 'cam1', 'cam2']):\n",
    "    K, d = load_kalibr_intrinsics(data, cam_key)\n",
    "    camera_calib_data[cam_key]['intrinsics']['K'] = K\n",
    "    camera_calib_data[cam_key]['intrinsics']['d'] = d\n",
    "\n",
    "    # extrinsics\n",
    "    if i > 0:\n",
    "        R, T = load_kalibr_extrinsics(data, cam_key)\n",
    "        camera_calib_data['stereo_extrinsics'][f'R_{i}_{i-1}'] = R\n",
    "        camera_calib_data['stereo_extrinsics'][f'T_{i}_{i-1}'] = T\n",
    "\n",
    "\n",
    "print(camera_calib_data)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "# print(\"Camera Calibration Data:\")\n",
    "# print(camera_calib_data['cam0']['intrinsics']['K'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kailbr yaml to py module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def load_T_cam0_world(path=\"T_cam0_world.npy\"):\n",
    "    return np.load(path)\n",
    "\n",
    "def parse_camchain_to_py_module(yaml_path, output_path=\"camera_calib_data.py\", T_cam0_world_path=\"T_cam0_world.npy\"):\n",
    "    with open(yaml_path, \"r\") as f:\n",
    "        data = yaml.safe_load(f)\n",
    "\n",
    "    if T_cam0_world_path is None:\n",
    "        T_cam0_world = np.eye(4)\n",
    "    else:\n",
    "        T_cam0_world = load_T_cam0_world(T_cam0_world_path)\n",
    "\n",
    "    output = \"import numpy as np\\n\\n\"\n",
    "    output += \"camera_calib_data = {\\n\"\n",
    "\n",
    "    cam_keys = sorted([k for k in data.keys() if k.startswith(\"cam\")])\n",
    "    T_cams_world = {}\n",
    "\n",
    "    for i, cam_key in enumerate(cam_keys):\n",
    "        cam = data[cam_key]\n",
    "        intrinsics = cam[\"intrinsics\"]\n",
    "        K = np.array([[intrinsics[0], 0, intrinsics[2]],\n",
    "                      [0, intrinsics[1], intrinsics[3]],\n",
    "                      [0, 0, 1]])\n",
    "        d = np.array(cam[\"distortion_coeffs\"]).reshape(1, -1)\n",
    "\n",
    "        output += f\"    '{cam_key}': {{\\n\"\n",
    "        output += f\"        'intrinsics': {{'K': np.array({repr(K.tolist())}), 'd': np.array({repr(d.tolist())})}},\\n\"\n",
    "\n",
    "        if i == 0:\n",
    "            T_world = T_cam0_world\n",
    "        else:\n",
    "            T_rel = np.array(cam[\"T_cn_cnm1\"])\n",
    "            T_prev = T_cams_world[cam_keys[i - 1]]\n",
    "            T_world = T_rel @ T_prev\n",
    "\n",
    "        R = T_world[:3, :3]\n",
    "        T = T_world[:3, 3].reshape(3, 1)\n",
    "        T_cams_world[cam_key] = T_world\n",
    "\n",
    "        output += f\"        'extrinsics': {{'R': np.array({repr(R.tolist())}), 'T': np.array({repr(T.tolist())})}},\\n\"\n",
    "        output += f\"    }},\\n\"\n",
    "\n",
    "    # Stereo extrinsics\n",
    "    T_1_0 = np.array(data['cam1']['T_cn_cnm1'])\n",
    "    R_1_0 = T_1_0[:3, :3]\n",
    "    T_1_0_vec = T_1_0[:3, 3].reshape(3, 1)\n",
    "\n",
    "    output += f\"    'stereo_extrinsics': {{'R_1_0': np.array({repr(R_1_0.tolist())}), \"\n",
    "    output += f\"'T_1_0': np.array({repr(T_1_0_vec.tolist())})}}\\n\"\n",
    "    output += \"}\\n\"\n",
    "\n",
    "    with open(output_path, \"w\") as f:\n",
    "        f.write(output)\n",
    "\n",
    "    print(f\"Saved calibration module to {output_path}\")\n",
    "\n",
    "# Example usage\n",
    "calib_id = \"08-04-25\"\n",
    "calib_base_folder = f\"/home/arclab/catkin_ws/src/Catheter-Perception/camera_calibration/{calib_id}\"\n",
    "os.makedirs(calib_base_folder, exist_ok=True)\n",
    "yaml_path = f\"/home/arclab/catkin_ws/src/kalibr/{calib_id}_calib-camchain.yaml\"\n",
    "T_world_path = os.path.join(calib_base_folder, \"T_cam0_world.npy\")\n",
    "output_path = os.path.join(calib_base_folder, \"camera_calib_data.py\")\n",
    "parse_camchain_to_py_module(yaml_path, output_path, T_world_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize world frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib.util\n",
    "# from camera_calib_data import *\n",
    "\n",
    "def draw_axes(img, K, d, R_wc, T_wc, axis_length=0.05):\n",
    "    origin = np.array([[0, 0, 0]], dtype=np.float32)\n",
    "    axes = np.float32([\n",
    "        [axis_length, 0, 0],\n",
    "        [0, axis_length, 0],\n",
    "        [0, 0, axis_length]\n",
    "    ])\n",
    "    pts_3d = np.vstack([origin, axes])\n",
    "    pts_cam = (R_wc @ pts_3d.T + T_wc).T\n",
    "    pts_2d, _ = cv2.projectPoints(pts_cam, np.zeros(3), np.zeros(3), K, d)\n",
    "    pts_2d = pts_2d.reshape(-1, 2)\n",
    "\n",
    "    origin = tuple(pts_2d[0].astype(int))\n",
    "    x_axis = tuple(pts_2d[1].astype(int))\n",
    "    y_axis = tuple(pts_2d[2].astype(int))\n",
    "    z_axis = tuple(pts_2d[3].astype(int))\n",
    "\n",
    "    cv2.line(img, origin, x_axis, (0, 0, 255), 2)\n",
    "    cv2.line(img, origin, y_axis, (0, 255, 0), 2)\n",
    "    cv2.line(img, origin, z_axis, (255, 0, 0), 2)\n",
    "    return img\n",
    "\n",
    "def visualize_world_axes_on_images(camera_calib_data, image_root=\".\", save_folder=None):\n",
    "\n",
    "    for cam_key in ['cam0', 'cam1', 'cam2']:\n",
    "        K = camera_calib_data[cam_key]['intrinsics']['K']\n",
    "        d = camera_calib_data[cam_key]['intrinsics']['d']\n",
    "        R = camera_calib_data[cam_key]['extrinsics']['R']\n",
    "        T = camera_calib_data[cam_key]['extrinsics']['T']\n",
    "        \n",
    "        rvec = cv2.Rodrigues(R)[0]\n",
    "        tvec = T.reshape(3, 1)\n",
    "\n",
    "        # for i in range(3):\n",
    "        img_path = os.path.join(image_root, f\"{cam_key}_0.png\")\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            print(f\"Could not load {img_path}\")\n",
    "            continue\n",
    "        img_axes = cv2.drawFrameAxes(img, K, d, rvec, tvec, length=0.05, thickness=2)\n",
    "        cv2.imshow(f\"{cam_key} World Axes\", img_axes)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "        # save_path = os.path.join(save_folder, f\"{cam_key}_world_axes.png\")\n",
    "        # cv2.imwrite(save_path, img_axes)\n",
    "        # print(f\"Saved {save_path}\")\n",
    "\n",
    "# Run the visualization\n",
    "visualize_world_axes_on_images(\n",
    "    camera_calib_data,\n",
    "    image_root=\"/home/arclab/catkin_ws/src/Catheter-Perception/camera_calibration/08-05-25/test_calib_images\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib.util\n",
    "\n",
    "def load_camera_calib_data(module_path):\n",
    "    spec = importlib.util.spec_from_file_location(\"camera_calib_data\", module_path)\n",
    "    calib_module = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(calib_module)\n",
    "    return calib_module.camera_calib_data\n",
    "\n",
    "def draw_axes_on_image(img, K, R, T, axis_length=0.05):\n",
    "    \"\"\"\n",
    "    Draws the 3D world coordinate axes on the 2D image using the given camera intrinsics and extrinsics.\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): The image to draw on.\n",
    "        K (np.ndarray): Camera intrinsics (3x3).\n",
    "        R (np.ndarray): Camera rotation matrix (3x3).\n",
    "        T (np.ndarray): Camera translation vector (3x1).\n",
    "        axis_length (float): Length of the axes in meters.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Image with axes drawn.\n",
    "    \"\"\"\n",
    "    # Define the 3D points in world frame\n",
    "    origin = np.zeros((3, 1))\n",
    "    x_axis = np.array([[axis_length, 0, 0]]).T\n",
    "    y_axis = np.array([[0, axis_length, 0]]).T\n",
    "    z_axis = np.array([[0, 0, axis_length]]).T\n",
    "\n",
    "    points_3D = np.hstack([origin, x_axis, y_axis, z_axis])  # shape (3, 4)\n",
    "\n",
    "    # Project to image using cv2.projectPoints (expects rvec, tvec)\n",
    "    rvec, _ = cv2.Rodrigues(R)\n",
    "    tvec = T\n",
    "\n",
    "    points_2D, _ = cv2.projectPoints(points_3D.T, rvec, tvec, K, None)\n",
    "    points_2D = points_2D.squeeze().astype(int)\n",
    "\n",
    "    origin_2D = tuple(points_2D[0])\n",
    "    x_2D = tuple(points_2D[1])\n",
    "    y_2D = tuple(points_2D[2])\n",
    "    z_2D = tuple(points_2D[3])\n",
    "\n",
    "    # Draw the axes\n",
    "    img = cv2.line(img, origin_2D, x_2D, (0, 0, 255), 2)  # X - red\n",
    "    img = cv2.line(img, origin_2D, y_2D, (0, 255, 0), 2)  # Y - green\n",
    "    img = cv2.line(img, origin_2D, z_2D, (255, 0, 0), 2)  # Z - blue\n",
    "\n",
    "    return img\n",
    "\n",
    "def visualize_axes_on_all_cameras(images_dict, camera_calib_data):\n",
    "    \"\"\"\n",
    "    Given a dict of images for each camera, overlay the world axes on each.\n",
    "\n",
    "    Args:\n",
    "        images_dict (dict): Dictionary of images with keys 'cam0', 'cam1', 'cam2'\n",
    "    \"\"\"\n",
    "    for cam_id in ['cam0', 'cam1', 'cam2']:\n",
    "        calib = camera_calib_data[cam_id]\n",
    "        K = calib['intrinsics']['K']\n",
    "        R = calib['extrinsics']['R']\n",
    "        T = calib['extrinsics']['T']\n",
    "\n",
    "        img = images_dict[cam_id].copy()\n",
    "        img_with_axes = draw_axes_on_image(img, K, R, T)\n",
    "\n",
    "        cv2.imshow(cam_id, img_with_axes)\n",
    "\n",
    "    print(\"Press any key to close...\")\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Load or capture an image for each camera\n",
    "    # Replace these with actual image frames from your cameras\n",
    "    root_dir = \"/home/arclab/catkin_ws/src/Catheter-Perception/camera_calibration/08-04-25\"\n",
    "    img0 = cv2.imread(f\"{root_dir}/cam0/img_000.png\")\n",
    "    img1 = cv2.imread(f\"{root_dir}/cam1/img_000.png\")\n",
    "    img2 = cv2.imread(f\"{root_dir}/cam2/img_000.png\")\n",
    "    calib_module_path=\"/home/arclab/catkin_ws/src/Catheter-Perception/camera_calibration/08-04-25/camera_calib_data.py\"\n",
    "    camera_calib_data = load_camera_calib_data(calib_module_path)\n",
    "\n",
    "    images = {'cam0': img0, 'cam1': img1, 'cam2': img2}\n",
    "    visualize_axes_on_all_cameras(images, camera_calib_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Camera Calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Intrinsics Charuco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute intrinsic, stereo extrinsic, and camera to world transforms\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2.aruco as aruco\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "def calibrate_intrinsics_charuco(glob_pattern, charuco_board, aruco_dict, min_markers=20):\n",
    "    '''\n",
    "    Calibrates camera intrinsics using a ChArUco board.\n",
    "    '''\n",
    "    all_corners, all_ids, img_size = [], [], None\n",
    "\n",
    "    for fname in glob.glob(glob_pattern):\n",
    "        img = cv2.imread(fname)\n",
    "        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        if img_size is None:\n",
    "            img_size = img_gray.shape[::-1]\n",
    "\n",
    "        detector = aruco.CharucoDetector(charuco_board)\n",
    "        charuco_corners, charuco_ids, marker_corners, marker_ids = detector.detectBoard(img_gray)\n",
    "\n",
    "        # ⛔️ Skip images with insufficient corner detections\n",
    "        if charuco_corners is None or charuco_ids is None or len(charuco_corners) < min_markers:\n",
    "            print(f\"Skipping {fname} - Not enough corners detected.\")\n",
    "            continue\n",
    "\n",
    "        all_corners.append(charuco_corners)\n",
    "        all_ids.append(charuco_ids)\n",
    "\n",
    "    # ✅ Only calibrate if you have enough valid detections\n",
    "    if len(all_corners) == 0:\n",
    "        raise ValueError(\"No valid ChArUco detections. Check your images or board setup.\")\n",
    "\n",
    "    # Calibrate\n",
    "    ret, K, dist, rvecs, tvecs = aruco.calibrateCameraCharuco(\n",
    "        charucoCorners=all_corners,\n",
    "        charucoIds=all_ids,\n",
    "        board=charuco_board,\n",
    "        imageSize=img_size,\n",
    "        cameraMatrix=None,\n",
    "        distCoeffs=None\n",
    "    )\n",
    "\n",
    "    return ret, K, dist, rvecs, tvecs\n",
    "\n",
    "\n",
    "# Dict holding all camera calibration data\n",
    "camera_calib_data = {\n",
    "        \"cam0\": {\n",
    "            \"intrinsics\": {\n",
    "                \"K\": None,\n",
    "                \"d\": None\n",
    "            },\n",
    "            \"extrinsics\": { # this is camera to world transform\n",
    "                \"R\": None,\n",
    "                \"T\": None\n",
    "            }\n",
    "        },\n",
    "        \"cam1\": {\n",
    "            \"intrinsics\": {\n",
    "                \"K\": None,\n",
    "                \"d\": None\n",
    "            },\n",
    "            \"extrinsics\": {\n",
    "                \"R\": None,\n",
    "                \"T\": None\n",
    "            }\n",
    "        },\n",
    "        \"stereo_extrinsics\": { # Camera to camera transform (from cam0 to cam1)\n",
    "            \"R_1_0\": None,\n",
    "            \"T_1_0\": None,\n",
    "            \"R_2_0\": None,\n",
    "            \"T_2_0\": None\n",
    "        }, \n",
    "        \"cam2\": {\n",
    "            \"intrinsics\": {\n",
    "                \"K\": None,\n",
    "                \"d\": None\n",
    "            },\n",
    "            \"extrinsics\": {\n",
    "                \"R\": None,\n",
    "                \"T\": None\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Define ChArUco board used\n",
    "square_size = 0.010\n",
    "marker_length = 0.006\n",
    "board_size = (10, 10)\n",
    "aruco_dict = aruco.getPredefinedDictionary(aruco.DICT_4X4_50)\n",
    "charuco_board_A = aruco.CharucoBoard(\n",
    "    size=board_size,\n",
    "    squareLength=square_size, \n",
    "    markerLength=marker_length,\n",
    "    dictionary=aruco_dict\n",
    ")\n",
    "\n",
    "charuco_board_B = aruco.CharucoBoard(\n",
    "    size=(10, 10),\n",
    "    squareLength=0.006, \n",
    "    markerLength=0.004,\n",
    "    dictionary=aruco_dict\n",
    ")\n",
    "\n",
    "# Calibrate instrinsics\n",
    "for i in range(3):\n",
    "    charuco_board = charuco_board_A if i < 2 else charuco_board_B\n",
    "    intrinsic_calib_images_path = f\"{calib_base_folder}/intrinsic_calib_images/cam{i}/*.png\"\n",
    "    rms_error, K, d, _, _ = calibrate_intrinsics_charuco(\n",
    "        intrinsic_calib_images_path, charuco_board, aruco_dict\n",
    "    )\n",
    "    print(f\"Charuco intrinsics for camera {i} RMS error: {rms_error:.4f}\")\n",
    "    print(f\"Camera {i} intrinsic matrix:\\n{K}\")\n",
    "    print(f\"Camera {i} distortion coefficients:\\n{d}\")\n",
    "    camera_calib_data[f\"cam{i}\"][\"intrinsics\"][\"K\"] = K\n",
    "    camera_calib_data[f\"cam{i}\"][\"intrinsics\"][\"d\"] = d\n",
    "\n",
    "print(\"Intrinsic calibration complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Stereo Extrinsics Charuco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2.aruco as aruco\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "\n",
    "def detect_charuco_corners(image_path, board, detector):\n",
    "    \"\"\"Detects Charuco corners using OpenCV 4.11+ functions.\"\"\"\n",
    "    img = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect Aruco markers and Charuco corners\n",
    "    charuco_corners, charuco_ids, _, _ = detector.detectBoard(gray)\n",
    "\n",
    "    if charuco_ids is not None and len(charuco_ids) > 4:\n",
    "        return charuco_corners, charuco_ids\n",
    "    return None, None\n",
    "\n",
    "def calculate_relative_transform(R1, T1, R2, T2):\n",
    "    \"\"\"Calculate the relative rotation and translation between two cameras.\n",
    "    Returns R21 and T21, the rotation and translation of camera 2 in camera 1's frame.\"\"\"\n",
    "    R21 = np.dot(R2, R1.T)\n",
    "    T21 = T2 - np.dot(R21, T1)\n",
    "    return R21, T21\n",
    "\n",
    "def get_extrinsics(image_path, K, dist, board, detector):\n",
    "    \"\"\"Compute extrinsics for a single image.\"\"\"\n",
    "    charuco_corners, charuco_ids = detect_charuco_corners(image_path, board, detector)\n",
    "    if charuco_corners is not None:\n",
    "        obj_points = board.getChessboardCorners()[charuco_ids.flatten()]\n",
    "        ret, rvec, tvec = cv2.solvePnP(obj_points, charuco_corners, K, dist)\n",
    "        if ret:\n",
    "            R, _ = cv2.Rodrigues(rvec)\n",
    "            return R, tvec\n",
    "    return None, None\n",
    "\n",
    "# # Load intrinsic parameters\n",
    "# calib_data_file = \"../camera_calibration/05-08-25/camera_calib_data.pkl\"\n",
    "# with open(calib_data_file, 'rb') as f:\n",
    "#     calib_data = pickle.load(f)\n",
    "\n",
    "K0 = camera_calib_data[\"cam0\"][\"intrinsics\"][\"K\"]\n",
    "dist0 = camera_calib_data[\"cam0\"][\"intrinsics\"][\"d\"]\n",
    "K1 = camera_calib_data[\"cam1\"][\"intrinsics\"][\"K\"]\n",
    "dist1 = camera_calib_data[\"cam1\"][\"intrinsics\"][\"d\"]\n",
    "\n",
    "# Define ChArUco board used\n",
    "square_size = 0.006\n",
    "marker_length = 0.004\n",
    "board_size = (10, 10)\n",
    "aruco_dict = aruco.getPredefinedDictionary(aruco.DICT_4X4_50)\n",
    "charuco_board = aruco.CharucoBoard(\n",
    "    size=board_size,\n",
    "    squareLength=square_size, \n",
    "    markerLength=marker_length,\n",
    "    dictionary=aruco_dict\n",
    ")\n",
    "\n",
    "# Create the Aruco and Charuco detector objects (new in OpenCV 4.11+)\n",
    "aruco_detector = aruco.ArucoDetector(aruco_dict)\n",
    "charuco_detector = aruco.CharucoDetector(charuco_board)\n",
    "\n",
    "# Paths to synchronized images\n",
    "cam0_images = sorted(glob.glob(f\"{calib_base_folder}/stereo_calib_images/cams_0_1/cam0_*.png\"))\n",
    "cam1_images = sorted(glob.glob(f\"{calib_base_folder}/stereo_calib_images/cams_0_1/cam1_*.png\"))\n",
    "\n",
    "# Arrays to store transformations\n",
    "relative_rotations = []\n",
    "relative_translations = []\n",
    "\n",
    "for img0_path, img1_path in zip(cam0_images, cam1_images):\n",
    "    # Get extrinsics for both cameras using updated functions\n",
    "    R0, T0 = get_extrinsics(img0_path, K0, dist0, charuco_board, charuco_detector)\n",
    "    R1, T1 = get_extrinsics(img1_path, K1, dist1, charuco_board, charuco_detector)\n",
    "\n",
    "    if R0 is not None and R1 is not None:\n",
    "        # Calculate the relative transformation between cameras\n",
    "        R10, T10 = calculate_relative_transform(R0, T0, R1, T1)\n",
    "        relative_rotations.append(R10)\n",
    "        relative_translations.append(T10)\n",
    "\n",
    "# Average the transformations\n",
    "R_avg = sum(relative_rotations) / len(relative_rotations)\n",
    "T_avg = sum(relative_translations) / len(relative_translations)\n",
    "\n",
    "# Print the averaged relative transformation\n",
    "print(\"Transform from Camera 0 to Camera 1:\")\n",
    "print(\"Averaged Relative Rotation (R10):\\n\", R_avg)\n",
    "print(\"Averaged Relative Translation (T10):\\n\", T_avg)\n",
    "\n",
    "# Save the relative transformation\n",
    "camera_calib_data[\"stereo_extrinsics\"][\"R_1_0\"] = R_avg\n",
    "camera_calib_data[\"stereo_extrinsics\"][\"T_1_0\"] = T_avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2.aruco as aruco\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "\n",
    "def detect_charuco_corners(image_path, board, detector):\n",
    "    \"\"\"Detects Charuco corners using OpenCV 4.11+ functions.\"\"\"\n",
    "    img = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect Aruco markers and Charuco corners\n",
    "    charuco_corners, charuco_ids, _, _ = detector.detectBoard(gray)\n",
    "\n",
    "    if charuco_ids is not None and len(charuco_ids) > 4:\n",
    "        return charuco_corners, charuco_ids\n",
    "    return None, None\n",
    "\n",
    "def calculate_relative_transform(R1, T1, R2, T2):\n",
    "    \"\"\"Calculate the relative rotation and translation between two cameras.\n",
    "    Returns R21 and T21, the rotation and translation of camera 2 in camera 1's frame.\"\"\"\n",
    "    R21 = np.dot(R2, R1.T)\n",
    "    T21 = T2 - np.dot(R21, T1)\n",
    "    return R21, T21\n",
    "\n",
    "def get_extrinsics(image_path, K, dist, board, detector):\n",
    "    \"\"\"Compute extrinsics for a single image.\"\"\"\n",
    "    charuco_corners, charuco_ids = detect_charuco_corners(image_path, board, detector)\n",
    "    if charuco_corners is not None:\n",
    "        obj_points = board.getChessboardCorners()[charuco_ids.flatten()]\n",
    "        ret, rvec, tvec = cv2.solvePnP(obj_points, charuco_corners, K, dist)\n",
    "        if ret:\n",
    "            R, _ = cv2.Rodrigues(rvec)\n",
    "            return R, tvec\n",
    "    return None, None\n",
    "\n",
    "# # Load intrinsic parameters\n",
    "# calib_data_file = \"../camera_calibration/05-08-25/camera_calib_data.pkl\"\n",
    "# with open(calib_data_file, 'rb') as f:\n",
    "#     calib_data = pickle.load(f)\n",
    "\n",
    "K0 = camera_calib_data[\"cam0\"][\"intrinsics\"][\"K\"]\n",
    "dist0 = camera_calib_data[\"cam0\"][\"intrinsics\"][\"d\"]\n",
    "K2 = camera_calib_data[\"cam2\"][\"intrinsics\"][\"K\"]\n",
    "dist2 = camera_calib_data[\"cam2\"][\"intrinsics\"][\"d\"]\n",
    "\n",
    "# Define ChArUco board used\n",
    "square_size = 0.006\n",
    "marker_length = 0.004\n",
    "board_size = (10, 10)\n",
    "aruco_dict = aruco.getPredefinedDictionary(aruco.DICT_4X4_50)\n",
    "charuco_board = aruco.CharucoBoard(\n",
    "    size=board_size,\n",
    "    squareLength=square_size, \n",
    "    markerLength=marker_length,\n",
    "    dictionary=aruco_dict\n",
    ")\n",
    "\n",
    "# Create the Aruco and Charuco detector objects (new in OpenCV 4.11+)\n",
    "aruco_detector = aruco.ArucoDetector(aruco_dict)\n",
    "charuco_detector = aruco.CharucoDetector(charuco_board)\n",
    "\n",
    "# Paths to synchronized images\n",
    "cam0_images = sorted(glob.glob(f\"{calib_base_folder}/stereo_calib_images/cams_0_2/cam0_*.png\"))\n",
    "cam1_images = sorted(glob.glob(f\"{calib_base_folder}/stereo_calib_images/cams_0_2/cam2_*.png\"))\n",
    "\n",
    "# Arrays to store transformations\n",
    "relative_rotations = []\n",
    "relative_translations = []\n",
    "\n",
    "for img0_path, img1_path in zip(cam0_images, cam1_images):\n",
    "    # Get extrinsics for both cameras using updated functions\n",
    "    R0, T0 = get_extrinsics(img0_path, K0, dist0, charuco_board, charuco_detector)\n",
    "    R1, T1 = get_extrinsics(img1_path, K1, dist1, charuco_board, charuco_detector)\n",
    "\n",
    "    if R0 is not None and R1 is not None:\n",
    "        # Calculate the relative transformation between cameras\n",
    "        R10, T10 = calculate_relative_transform(R0, T0, R1, T1)\n",
    "        relative_rotations.append(R10)\n",
    "        relative_translations.append(T10)\n",
    "\n",
    "# Average the transformations\n",
    "R_avg = sum(relative_rotations) / len(relative_rotations)\n",
    "T_avg = sum(relative_translations) / len(relative_translations)\n",
    "\n",
    "# Print the averaged relative transformation\n",
    "print(\"Transform from Camera 0 to Camera 2:\")\n",
    "print(\"Averaged Relative Rotation (R10):\\n\", R_avg)\n",
    "print(\"Averaged Relative Translation (T10):\\n\", T_avg)\n",
    "\n",
    "# Save the relative transformation\n",
    "camera_calib_data[\"stereo_extrinsics\"][\"R_2_0\"] = R_avg\n",
    "camera_calib_data[\"stereo_extrinsics\"][\"T_2_0\"] = T_avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute World Transform Charuco Board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.05]\n",
      " [0.08]\n",
      " [0.  ]]\n",
      "Camera cam0 extrinsic calibration complete.\n",
      "R = \n",
      " [[ 0.02125371  0.99865781 -0.04723202]\n",
      " [-0.99973489  0.02164761  0.00784379]\n",
      " [ 0.00885572  0.04705279  0.99885315]]\n",
      "T = \n",
      " [[-0.00252137]\n",
      " [-0.00207384]\n",
      " [ 0.15525986]]\n",
      "{'cam0': {'intrinsics': {'K': array([[939.00659834,   0.        , 610.34435618],\n",
      "       [  0.        , 938.71208314, 380.19234786],\n",
      "       [  0.        ,   0.        ,   1.        ]]), 'd': array([ 0.02409601, -0.11651624,  0.00295776, -0.00425454])}, 'extrinsics': {'R': array([[ 0.02125371,  0.99865781, -0.04723202],\n",
      "       [-0.99973489,  0.02164761,  0.00784379],\n",
      "       [ 0.00885572,  0.04705279,  0.99885315]]), 'T': array([[-0.00252137],\n",
      "       [-0.00207384],\n",
      "       [ 0.15525986]])}}, 'cam1': {'intrinsics': {'K': array([[946.71215549,   0.        , 635.97087467],\n",
      "       [  0.        , 947.54229082, 378.04191205],\n",
      "       [  0.        ,   0.        ,   1.        ]]), 'd': array([ 0.03397451, -0.09771331,  0.00017749, -0.00423783])}, 'extrinsics': {'R': array([[-0.99922506,  0.00966103,  0.0381569 ],\n",
      "       [-0.03830797, -0.01596747, -0.9991384 ],\n",
      "       [-0.00904344, -0.99982584,  0.0163252 ]]), 'T': array([[-0.00813243],\n",
      "       [-0.01443068],\n",
      "       [ 0.13755457]])}}, 'stereo_extrinsics': {'R_1_0': array([[-0.0133914 ,  0.99946859,  0.02971885],\n",
      "       [ 0.0304311 ,  0.03011512, -0.99908309],\n",
      "       [-0.99944716, -0.01247474, -0.03081821]]), 'T_1_0': array([[-0.0107076 ],\n",
      "       [ 0.14082601],\n",
      "       [ 0.13979356]]), 'R_2_1': array([[-0.02680169,  0.04737187, -0.99851769],\n",
      "       [ 0.02715598,  0.99854238,  0.04664413],\n",
      "       [ 0.99927185, -0.02586558, -0.02804905]]), 'T_2_1': array([[0.13355559],\n",
      "       [0.00672306],\n",
      "       [0.16317674]])}, 'cam2': {'intrinsics': {'K': array([[948.77457332,   0.        , 632.33643371],\n",
      "       [  0.        , 950.22636982, 364.02619265],\n",
      "       [  0.        ,   0.        ,   1.        ]]), 'd': array([ 0.04326954, -0.12884495,  0.00301781,  0.00080879])}, 'extrinsics': {'R': array([[ 0.03399623,  0.99732844, -0.06465472],\n",
      "       [-0.06580889, -0.06231785, -0.99588437],\n",
      "       [-0.99725295,  0.03811117,  0.0635145 ]]), 'T': array([[-0.00426073],\n",
      "       [-0.00149132],\n",
      "       [ 0.15156521]])}}}\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import cv2.aruco as aruco\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "def compute_camera_to_world_transform(image_path, cam_key, camera_calib_data, charuco_board, origin_idx=0, visualize=True):\n",
    "    \"\"\"\n",
    "    Estimates the camera-to-world transform using a ChArUco board, and draws world frame axes at a specified corner.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to the image showing the ChArUco board.\n",
    "        cam_key (str): 'cam0', 'cam1', or 'cam2'\n",
    "        camera_calib_data (dict): Dictionary holding K, d, and will be updated with R, T.\n",
    "        charuco_board (cv2.aruco.CharucoBoard): The ChArUco board definition.\n",
    "        origin_idx (int): Index of the ChArUco corner to use as the world origin.\n",
    "        visualize (bool): Whether to display image with drawn corners and axes.\n",
    "    \"\"\"\n",
    "\n",
    "    # === Get intrinsics ===\n",
    "    K = camera_calib_data[cam_key][\"intrinsics\"][\"K\"]\n",
    "    d = camera_calib_data[cam_key][\"intrinsics\"][\"d\"]\n",
    "    if K is None or d is None:\n",
    "        raise ValueError(f\"Missing intrinsics for {cam_key}\")\n",
    "\n",
    "    # === Read image ===\n",
    "    img = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # === Detect board ===\n",
    "    detector = aruco.CharucoDetector(charuco_board)\n",
    "    charuco_corners, charuco_ids, marker_corners, marker_ids = detector.detectBoard(gray)\n",
    "\n",
    "    if charuco_corners is None or charuco_ids is None or len(charuco_corners) < 4:\n",
    "        raise RuntimeError(\"ChArUco board detection failed or not enough corners.\")\n",
    "\n",
    "    # === Estimate pose of board ===\n",
    "    retval, rvec, tvec = aruco.estimatePoseCharucoBoard(\n",
    "        charuco_corners, charuco_ids, charuco_board, K, d, None, None\n",
    "    )\n",
    "    if not retval:\n",
    "        raise RuntimeError(\"Pose estimation failed.\")\n",
    "\n",
    "    # === Convert rotation vector to matrix ===\n",
    "    R, _ = cv2.Rodrigues(rvec)\n",
    "    T = tvec.reshape((3, 1))\n",
    "\n",
    "    # === Adjust world origin if origin_idx is visible ===\n",
    "    detected_ids = charuco_ids.flatten()\n",
    "    if origin_idx in detected_ids:\n",
    "        origin_corner_in_board = charuco_board.getChessboardCorners()[origin_idx].reshape(3, 1)\n",
    "        print(origin_corner_in_board)\n",
    "        T = T + R @ origin_corner_in_board\n",
    "        adjusted_tvec = tvec + R @ origin_corner_in_board\n",
    "    else:\n",
    "        print(f\"Warning: origin_idx {origin_idx} not found in detected IDs. Using default origin.\")\n",
    "        adjusted_tvec = tvec\n",
    "\n",
    "    # === Store extrinsics into the camera_calib_data dict ===\n",
    "    camera_calib_data[cam_key][\"extrinsics\"][\"R\"] = R\n",
    "    camera_calib_data[cam_key][\"extrinsics\"][\"T\"] = T\n",
    "\n",
    "    print(f\"Camera {cam_key} extrinsic calibration complete.\")\n",
    "    print(\"R = \\n\", R)\n",
    "    print(\"T = \\n\", T)\n",
    "\n",
    "    # === Visualization ===\n",
    "    if visualize:\n",
    "        img_display = img.copy()\n",
    "        aruco.drawDetectedCornersCharuco(img_display, charuco_corners, charuco_ids, (0, 255, 0))\n",
    "\n",
    "        # Draw frame axes at the new origin (charuco corner specified by origin_idx)\n",
    "        axis_length = 0.03  # 3 cm\n",
    "        cv2.drawFrameAxes(img_display, K, d, rvec, adjusted_tvec, axis_length)\n",
    "\n",
    "        cv2.imshow(f\"{cam_key} - ChArUco + Axes at corner {origin_idx}\", img_display)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    return R, T\n",
    "\n",
    "\n",
    "image_path = f\"{calib_base_folder}/cam0_world_transform/img_000.png\"\n",
    "charuco_board = aruco.CharucoBoard(\n",
    "    size=(10, 10),\n",
    "    squareLength=0.010,\n",
    "    markerLength=0.006,\n",
    "    dictionary=aruco.getPredefinedDictionary(aruco.DICT_4X4_50)\n",
    ")\n",
    "# Compute camera to world transform for cam0\n",
    "R_0_w, T_0_w = compute_camera_to_world_transform(\n",
    "    image_path, \"cam0\", camera_calib_data, charuco_board, origin_idx=67\n",
    ")\n",
    "\n",
    "# Chain transforms to get world transforms for cams 1 and 2\n",
    "R_1_0 = camera_calib_data[\"stereo_extrinsics\"][\"R_1_0\"]\n",
    "T_1_0 = camera_calib_data[\"stereo_extrinsics\"][\"T_1_0\"]\n",
    "R_2_1 = camera_calib_data[\"stereo_extrinsics\"][\"R_2_1\"]\n",
    "T_2_1 = camera_calib_data[\"stereo_extrinsics\"][\"T_2_1\"]\n",
    "R_1_w = R_1_0 @ R_0_w\n",
    "T_1_w = R_1_0 @ T_0_w + T_1_0\n",
    "R_2_w = R_2_1 @ R_1_0 @ R_0_w\n",
    "T_2_0 = R_2_1 @ T_1_0 + T_2_1\n",
    "T_2_w =  R_2_1 @ T_1_w + T_2_1\n",
    "# Store the transforms\n",
    "camera_calib_data[\"cam1\"][\"extrinsics\"][\"R\"] = R_1_w\n",
    "camera_calib_data[\"cam1\"][\"extrinsics\"][\"T\"] = T_1_w\n",
    "camera_calib_data[\"cam2\"][\"extrinsics\"][\"R\"] = R_2_w\n",
    "camera_calib_data[\"cam2\"][\"extrinsics\"][\"T\"] = T_2_w\n",
    "\n",
    "print(camera_calib_data)\n",
    "\n",
    "# Save the camera calibration data to a file\n",
    "with open(f\"{calib_base_folder}/camera_calib_data.pkl\", 'wb') as f:\n",
    "    pickle.dump(camera_calib_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Camera-World Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find camera to world using PnP and calibrator piece\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "img_dir = \"../camera_calibration/05-16-25/extrinsic_calib_images\"\n",
    "img0 = cv2.imread(os.path.join(img_dir, \"cam0_0.png\"))\n",
    "img1 = cv2.imread(os.path.join(img_dir, \"cam1_0.png\"))\n",
    "# Downsize images for display\n",
    "img0 = cv2.resize(img0, (640, 480))\n",
    "img1 = cv2.resize(img1, (640, 480))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Lists to store clicked points\n",
    "points_img0 = []\n",
    "points_img1 = []\n",
    "\n",
    "def click_event_img0(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        points_img0.append((x, y))\n",
    "        print(f\"Image 0: Point {len(points_img0)}: ({x}, {y})\")\n",
    "        cv2.circle(img0, (x, y), 5, (0, 0, 255), -1)\n",
    "        cv2.imshow(\"Cam0\", img0)\n",
    "\n",
    "def click_event_img1(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        points_img1.append((x, y))\n",
    "        print(f\"Image 1: Point {len(points_img1)}: ({x}, {y})\")\n",
    "        cv2.circle(img1, (x, y), 5, (0, 0, 255), -1)\n",
    "        cv2.imshow(\"Cam1\", img1)\n",
    "\n",
    "cv2.imshow(\"Cam0\", img0)\n",
    "cv2.setMouseCallback(\"Cam0\", click_event_img0)\n",
    "cv2.imshow(\"Cam1\", img1)\n",
    "cv2.setMouseCallback(\"Cam1\", click_event_img1)\n",
    "\n",
    "print(\"Click points in both images. Press any key to finish and close windows.\")\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"Points in img0:\", points_img0)\n",
    "print(\"Points in img1:\", points_img1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in camera intrinsics\n",
    "with open(\"../camera_calibration/05-08-25/camera_calib_data.pkl\", 'rb') as f:\n",
    "    camera_calib_data = pickle.load(f)\n",
    "K0 = camera_calib_data[\"cam0\"][\"intrinsics\"][\"K\"]\n",
    "dist0 = camera_calib_data[\"cam0\"][\"intrinsics\"][\"d\"]\n",
    "K1 = camera_calib_data[\"cam1\"][\"intrinsics\"][\"K\"]\n",
    "dist1 = camera_calib_data[\"cam1\"][\"intrinsics\"][\"d\"]\n",
    "\n",
    "# Defined corresponding world frame coordinates of clicked points\n",
    "# These should be in the same order as the clicked points\n",
    "world_coords_0 = np.array([[0, 4.125, 0],\n",
    "                [0, 16, 9],\n",
    "                [0, 0, 23.95],\n",
    "                [-4.125, 0, 0],\n",
    "                [-16, 0, 9],\n",
    "                [4.125, 0, 0],\n",
    "                [16, 0, 9]]) / 1000\n",
    "\n",
    "world_coords_1 = np.array([[0, 4.125, 0],\n",
    "                [0, 16, 9],\n",
    "                [0, 0, 23.95],\n",
    "                [-4.125, 0, 0],\n",
    "                [-16, 0, 9],\n",
    "                [0, -4.125, 0],\n",
    "                [0, -16, 9]]) / 1000\n",
    "\n",
    "# Find world frame transform for each camera using solvePnP\n",
    "def find_camera_to_world_transform(points_img, world_coords, K, dist):\n",
    "    # Convert points to numpy arrays\n",
    "    points_img = np.array(points_img, dtype=np.float32)\n",
    "    world_coords = np.array(world_coords, dtype=np.float32)\n",
    "\n",
    "    # Solve PnP\n",
    "    _, rvec, tvec = cv2.solvePnP(world_coords, points_img, K, dist)\n",
    "    R, _ = cv2.Rodrigues(rvec)\n",
    "    return R, tvec\n",
    "\n",
    "R0, T0 = find_camera_to_world_transform(points_img0, world_coords_0, K0, dist0)\n",
    "R1, T1 = find_camera_to_world_transform(points_img1, world_coords_1, K1, dist1)\n",
    "print(\"Camera 0 to world transform:\")\n",
    "print(\"Rotation:\\n\", R0)\n",
    "print(\"Translation:\\n\", T0)\n",
    "print(\"Camera 1 to world transform:\")\n",
    "print(\"Rotation:\\n\", R1)\n",
    "print(\"Translation:\\n\", T1)\n",
    "\n",
    "# Visualize world frame axes in each camera frame\n",
    "def draw_axes(image, R, T, K, dist, axis_length=0.02):\n",
    "    \"\"\"Draw the world frame axes on the image.\"\"\"\n",
    "    axis_points = np.float32([\n",
    "        [0, 0, 0],                  # Origin\n",
    "        [axis_length, 0, 0],        # X-axis (red)\n",
    "        [0, axis_length, 0],        # Y-axis (green)\n",
    "        [0, 0, axis_length]         # Z-axis (blue)\n",
    "    ]).reshape(-1, 3)\n",
    "    img_points, _ = cv2.projectPoints(axis_points, cv2.Rodrigues(R)[0], T, K, dist)\n",
    "    origin = tuple(img_points[0].ravel().astype(int))\n",
    "    cv2.line(image, origin, tuple(img_points[1].ravel().astype(int)), (0, 0, 255), 3)\n",
    "    cv2.line(image, origin, tuple(img_points[2].ravel().astype(int)), (0, 255, 0), 3)\n",
    "    cv2.line(image, origin, tuple(img_points[3].ravel().astype(int)), (255, 0, 0), 3)\n",
    "    cv2.putText(image, \"X\", tuple(img_points[1].ravel().astype(int)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "    cv2.putText(image, \"Y\", tuple(img_points[2].ravel().astype(int)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.putText(image, \"Z\", tuple(img_points[3].ravel().astype(int)), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "\n",
    "# # Replace extrinsic calibration parameters\n",
    "# camera_calib_data[\"cam0\"][\"extrinsics\"][\"R\"] = R0\n",
    "# camera_calib_data[\"cam0\"][\"extrinsics\"][\"T\"] = T0\n",
    "# camera_calib_data[\"cam1\"][\"extrinsics\"][\"R\"] = R1\n",
    "# camera_calib_data[\"cam1\"][\"extrinsics\"][\"T\"] = T1\n",
    "# # Save the camera calibration data\n",
    "# with open(f\"../camera_calibration/05-16-25/camera_calib_data.pkl\", 'wb') as f:\n",
    "#     pickle.dump(camera_calib_data, f)\n",
    "\n",
    "# Show camera 0 world frame transform in both camera frames\n",
    "# Compute Camera 1 to world transform using stereo extrinsics\n",
    "R_1_0 = camera_calib_data[\"stereo_extrinsics\"][\"R_1_0\"]\n",
    "T_1_0 = camera_calib_data[\"stereo_extrinsics\"][\"T_1_0\"]\n",
    "R1_from0 = np.dot(R_1_0, R0)\n",
    "T1_from0 = np.dot(R_1_0, T0) + T_1_0\n",
    "print(\"Camera 1 to world transform using stereo extrinsics:\")\n",
    "print(\"Rotation:\\n\", R1_from0)\n",
    "print(\"Translation:\\n\", T1_from0)\n",
    "# Show camera 1 world frame transform in both camera frames\n",
    "R0_from1 = np.dot(R_1_0.T, R1)\n",
    "T0_from1 = np.dot(R_1_0.T, T1) - T_1_0\n",
    "print(\"Camera 0 to world transform using stereo extrinsics:\")\n",
    "print(\"Rotation:\\n\", R0_from1)\n",
    "print(\"Translation:\\n\", T0_from1)\n",
    "\n",
    "# Draw axes on img0 and img1\n",
    "# draw_axes(img0, R0, T0, K0, dist0)\n",
    "draw_axes(img0, R0_from1, T0_from1, K0, dist0)\n",
    "cv2.imshow(\"Camera 0 - World Frame Axes from cam 0 transform\", img0)\n",
    "# cv2.imshow(\"Camera 1 - World Frame Axes from cam 0 transform\", img1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Draw axes on img0 and img1\n",
    "# draw_axes(img1, R1_from0, T1_from0, K1, dist1)\n",
    "draw_axes(img1, R1, T1, K1, dist1)\n",
    "# cv2.imshow(\"Camera 0 - World Frame Axes from cam 1 transform\", img0)\n",
    "cv2.imshow(\"Camera 1 - World Frame Axes from cam 1 transform\", img1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def transform_matrix(R, t):\n",
    "    \"\"\"Construct a homogeneous transformation matrix from rotation and translation.\"\"\"\n",
    "    T = np.eye(4)\n",
    "    T[:3, :3] = R\n",
    "    T[:3, 3] = t\n",
    "    return T\n",
    "\n",
    "def check_transform_equivalence(R1, t1, R2, t2):\n",
    "    \"\"\"Check if two transformations are equivalent.\"\"\"\n",
    "    # Construct transformation matrices\n",
    "    T1 = transform_matrix(R1, t1)\n",
    "    T2 = transform_matrix(R2, t2)\n",
    "    \n",
    "    # Compute the relative transformation\n",
    "    relative_transform = np.linalg.inv(T1) @ T2\n",
    "    identity_matrix = np.eye(4)\n",
    "    \n",
    "    # Compute the deviation from the identity matrix\n",
    "    deviation = np.linalg.norm(relative_transform - identity_matrix)\n",
    "\n",
    "    # Print the relative transformation and the deviation\n",
    "    print(\"Relative Transformation:\\n\", relative_transform)\n",
    "    print(\"Deviation from Identity:\", deviation)\n",
    "\n",
    "    # Threshold for considering them equivalent\n",
    "    tolerance = 1e-6\n",
    "    if deviation < tolerance:\n",
    "        print(\"The transformations are approximately equivalent.\")\n",
    "    else:\n",
    "        print(\"The transformations are not equivalent.\")\n",
    "\n",
    "# # Example usage\n",
    "# R1 = np.array([[-0.996, -0.087, 0.012],\n",
    "#                [-0.032, 0.234, -0.972],\n",
    "#                [0.082, -0.968, -0.236]])\n",
    "\n",
    "# t1 = np.array([-0.003, 0.045, -0.221])\n",
    "\n",
    "# R2 = np.array([[-0.104, -0.994, 0.029],\n",
    "#                [-0.080, -0.020, -0.997],\n",
    "#                [0.991, -0.106, -0.078]])\n",
    "\n",
    "# t2 = np.array([0.015, 0.028, -0.273])\n",
    "\n",
    "check_transform_equivalence(R1, T0.flatten(), R0_from1, T0_from1.flatten())\n",
    "check_transform_equivalence(R1, T1.flatten(), R1_from0, T1_from0.flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import least_squares\n",
    "import pdb\n",
    "\n",
    "### Currently does not work\n",
    "\n",
    "def rotation_matrix_to_vector(R):\n",
    "    \"\"\"Convert a rotation matrix to a rotation vector using Rodrigues' formula.\"\"\"\n",
    "    rvec, _ = cv2.Rodrigues(R)\n",
    "    return rvec.flatten()\n",
    "\n",
    "\n",
    "def vector_to_rotation_matrix(rvec):\n",
    "    \"\"\"Convert a rotation vector to a rotation matrix using Rodrigues' formula.\"\"\"\n",
    "    R, _ = cv2.Rodrigues(rvec)\n",
    "    return R\n",
    "\n",
    "\n",
    "def transform_matrix(R, t):\n",
    "    \"\"\"Construct a homogeneous transformation matrix from rotation and translation.\"\"\"\n",
    "    T = np.eye(4)\n",
    "    T[:3, :3] = R\n",
    "    T[:3, 3] = t\n",
    "    return T\n",
    "\n",
    "\n",
    "def decompose_transform(T):\n",
    "    \"\"\"Decompose a transformation matrix into rotation and translation.\"\"\"\n",
    "    R = T[:3, :3]\n",
    "    t = T[:3, 3]\n",
    "    return R, t\n",
    "\n",
    "\n",
    "def cost_function(params, R_0_w, T_0_W, R_1_0, T_1_0, R_1_w, T_1_W):\n",
    "    \"\"\"Cost function to minimize the difference between expected and actual transforms.\"\"\"\n",
    "    rvec0, rvec1, t0, t1 = np.split(params, [3, 6, 9])\n",
    "    R0 = vector_to_rotation_matrix(rvec0)\n",
    "    R1 = vector_to_rotation_matrix(rvec1)\n",
    "    T0 = transform_matrix(R0, t0)\n",
    "    T1 = transform_matrix(R1, t1)\n",
    "    expected_T1 = T0 @ transform_matrix(R_1_0, T_1_0)\n",
    "    residual = (T1 - expected_T1).flatten()\n",
    "    return residual\n",
    "\n",
    "\n",
    "def refine_transforms(R_0_w, T_0_W, R_1_0, T_1_0, R_1_w, T_1_W):\n",
    "    \"\"\"Optimize transforms to improve consistency.\"\"\"\n",
    "    rvec0 = rotation_matrix_to_vector(R_0_w)\n",
    "    rvec1 = rotation_matrix_to_vector(R_1_w)\n",
    "    # pdb.set_trace()\n",
    "    initial_params = np.hstack([rvec0, rvec1, T_0_W, T_1_W])\n",
    "    result = least_squares(cost_function, initial_params, args=(R_0_w, T_0_W, R_1_0, T_1_0, R_1_w, T_1_W))\n",
    "    rvec0_opt, rvec1_opt, t0_opt, t1_opt = np.split(result.x, [3, 6, 9])\n",
    "    R0_opt = vector_to_rotation_matrix(rvec0_opt)\n",
    "    R1_opt = vector_to_rotation_matrix(rvec1_opt)\n",
    "    return R0_opt, t0_opt, R1_opt, t1_opt\n",
    "\n",
    "# Load the camera calibration data\n",
    "with open(f\"../camera_calibration/05-16-25/camera_calib_data.pkl\", 'rb') as f:\n",
    "    camera_calib_data = pickle.load(f)\n",
    "\n",
    "R_0_w = camera_calib_data[\"cam0\"][\"extrinsics\"][\"R\"]\n",
    "T_0_W = camera_calib_data[\"cam0\"][\"extrinsics\"][\"T\"].flatten()\n",
    "R_1_0 = camera_calib_data[\"stereo_extrinsics\"][\"R_1_0\"]\n",
    "T_1_0 = camera_calib_data[\"stereo_extrinsics\"][\"T_1_0\"].flatten()\n",
    "R_1_w = camera_calib_data[\"cam1\"][\"extrinsics\"][\"R\"]\n",
    "T_1_W = camera_calib_data[\"cam1\"][\"extrinsics\"][\"T\"].flatten()\n",
    "# Refine the transforms\n",
    "R0_refined, T0_refined, R1_refined, T1_refined = refine_transforms(R_0_w, T_0_W, R_1_0, T_1_0, R_1_w, T_1_W)\n",
    "print(\"Refined R_0_w:\\n\", R0_refined)\n",
    "print(\"Refined T_0_W:\\n\", T0_refined)\n",
    "print(\"Refined R_1_w:\\n\", R1_refined)\n",
    "print(\"Refined T_1_W:\\n\", T1_refined)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aruco marker world frame calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import cv2.aruco as aruco\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "def solve_pnp(marker_corners, marker_length, K, dist):\n",
    "    \"\"\"Solve PnP for a single Aruco marker.\"\"\"\n",
    "    half_length = marker_length / 2\n",
    "\n",
    "    # 3D points of the marker corners in the world coordinate system (origin at one corner)\n",
    "    obj_points = np.array([\n",
    "        [0, 0, 0],                  # Bottom-left (origin)\n",
    "        [marker_length, 0, 0],      # Bottom-right (X-axis)\n",
    "        [marker_length, marker_length, 0], # Top-right\n",
    "        [0, marker_length, 0]       # Top-left (Z-axis)\n",
    "    ], dtype=np.float32)\n",
    "    print(\"Object points:\\n\", obj_points)\n",
    "    # Solve PnP to find rotation and translation\n",
    "    ret, rvec, tvec = cv2.solvePnP(obj_points, marker_corners, K, dist)\n",
    "    if ret:\n",
    "        R, _ = cv2.Rodrigues(rvec)\n",
    "        return R, tvec\n",
    "    return None, None\n",
    "\n",
    "def draw_axes(image, R, T, K, dist):\n",
    "    \"\"\"Draw the world frame origin and axes on the image.\"\"\"\n",
    "    axis_length = 0.05  # 5 cm\n",
    "\n",
    "    # Define the 3D points for the axes\n",
    "    axis_points = np.float32([\n",
    "        [0, 0, 0],              # Origin\n",
    "        [axis_length, 0, 0],    # X-axis (red)\n",
    "        [0, axis_length, 0],    # Y-axis (green)\n",
    "        [0, 0, axis_length]     # Z-axis (blue)\n",
    "    ]).reshape(-1, 3)\n",
    "\n",
    "    # Project the 3D axis points onto the image plane\n",
    "    img_points, _ = cv2.projectPoints(axis_points, cv2.Rodrigues(R)[0], T, K, dist)\n",
    "\n",
    "    # Draw the origin point\n",
    "    origin = tuple(img_points[0].ravel().astype(int))\n",
    "    cv2.circle(image, origin, 5, (0, 0, 255), -1)\n",
    "\n",
    "    # Draw the X, Y, Z axes\n",
    "    cv2.line(image, origin, tuple(img_points[1].ravel().astype(int)), (0, 0, 255), 3)  # X-axis (red)\n",
    "    cv2.line(image, origin, tuple(img_points[2].ravel().astype(int)), (0, 255, 0), 3)  # Y-axis (green)\n",
    "    cv2.line(image, origin, tuple(img_points[3].ravel().astype(int)), (255, 0, 0), 3)  # Z-axis (blue)\n",
    "\n",
    "    # Annotate the axes\n",
    "    cv2.putText(image, \"X\", tuple(img_points[1].ravel().astype(int)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "    cv2.putText(image, \"Y\", tuple(img_points[2].ravel().astype(int)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.putText(image, \"Z\", tuple(img_points[3].ravel().astype(int)), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "\n",
    "# Load intrinsic calibration data\n",
    "# # Load intrinsic parameters\n",
    "calib_data_file = f\"../camera_calibration/05-08-25/camera_calib_data.pkl\"\n",
    "with open(calib_data_file, 'rb') as f:\n",
    "    camera_calib_data = pickle.load(f)\n",
    "\n",
    "K = camera_calib_data[\"cam0\"][\"intrinsics\"][\"K\"]\n",
    "dist = camera_calib_data[\"cam0\"][\"intrinsics\"][\"d\"]\n",
    "\n",
    "\n",
    "# Aruco marker parameters\n",
    "aruco_dict = aruco.getPredefinedDictionary(aruco.DICT_4X4_50)\n",
    "marker_length = 0.004  # Length of the marker side in meters\n",
    "\n",
    "# Initialize the Aruco detector\n",
    "detector = aruco.ArucoDetector(aruco_dict)\n",
    "\n",
    "# Load image\n",
    "img = cv2.imread(f\"../camera_calibration/05-08-25/extrinsic_calib_images/cam0/img_aruco.png\")\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detect the Aruco marker\n",
    "corners, ids, _ = detector.detectMarkers(img_gray)\n",
    "print(corners)\n",
    "\n",
    "if ids is not None:\n",
    "    R_0_w, T_0_w = solve_pnp(corners[0], marker_length, K, dist)\n",
    "    if R_0_w is not None:\n",
    "        print(f\"Camera 0 to World Rotation:\\n{R_0_w}\")\n",
    "        print(f\"Camera 0 to World Translation:\\n{T_0_w}\")\n",
    "\n",
    "        # Draw the marker and the world frame\n",
    "        aruco.drawDetectedMarkers(img, corners, ids)\n",
    "        draw_axes(img, R_0_w, T_0_w, K, dist)\n",
    "\n",
    "# Compute Camera 1 to world transform using stereo extrinsics\n",
    "R_1_0 = camera_calib_data[\"stereo_extrinsics\"][\"R_1_0\"]\n",
    "T_1_0 = camera_calib_data[\"stereo_extrinsics\"][\"T_1_0\"]\n",
    "R_1_w = np.dot(R_1_0, R_0_w)\n",
    "T_1_w = np.dot(R_1_0, T_0_w) + T_1_0\n",
    "print(f\"Camera 1 to World Rotation:\\n{R_1_w}\")\n",
    "print(f\"Camera 1 to World Translation:\\n{T_1_w}\")\n",
    "\n",
    "# save all calibration data\n",
    "camera_calib_data[\"cam0\"][\"extrinsics\"][\"R\"] = R_0_w\n",
    "camera_calib_data[\"cam0\"][\"extrinsics\"][\"T\"] = T_0_w\n",
    "camera_calib_data[\"cam1\"][\"extrinsics\"][\"R\"] = R_1_w\n",
    "camera_calib_data[\"cam1\"][\"extrinsics\"][\"T\"] = T_1_w\n",
    "\n",
    "# with open(f\"{calib_base_folder}/camera_calib_data.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(camera_calib_data, f)\n",
    "\n",
    "cv2.imshow(\"Camera 0 - Aruco Marker with World Frame\", img)\n",
    "# cv2.imwrite(f\"{calib_base_folder}/extrinsic_calib_images/cam0/img_aruco_with_axes.png\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify camera to world transform by projecting axes onto image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import cv2.aruco as aruco\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Load calibration data\n",
    "with open(f\"../camera_calibration/05-08-25/camera_calib_data.pkl\", \"rb\") as f:\n",
    "    camera_calib_data = pickle.load(f)\n",
    "\n",
    "# Load intrinsic and extrinsic parameters for both cameras\n",
    "K0 = camera_calib_data[\"cam0\"][\"intrinsics\"][\"K\"]\n",
    "dist0 = camera_calib_data[\"cam0\"][\"intrinsics\"][\"d\"]\n",
    "R_0_w = camera_calib_data[\"cam0\"][\"extrinsics\"][\"R\"]\n",
    "T_0_w = camera_calib_data[\"cam0\"][\"extrinsics\"][\"T\"]\n",
    "print(\"Camera 0 to World Rotation:\\n\", R_0_w)\n",
    "print(\"Camera 0 to World Translation:\\n\", T_0_w)\n",
    "\n",
    "K1 = camera_calib_data[\"cam1\"][\"intrinsics\"][\"K\"]\n",
    "dist1 = camera_calib_data[\"cam1\"][\"intrinsics\"][\"d\"]\n",
    "R_1_w = camera_calib_data[\"cam1\"][\"extrinsics\"][\"R\"]\n",
    "T_1_w = camera_calib_data[\"cam1\"][\"extrinsics\"][\"T\"]\n",
    "print(\"Camera 1 to World Rotation:\\n\", R_1_w)\n",
    "print(\"Camera 1 to World Translation:\\n\", T_1_w)\n",
    "\n",
    "# Load images for verification\n",
    "img0 = cv2.imread(f\"../tip_pose_images/cam0_0.png\")\n",
    "img1 = cv2.imread(f\"../tip_pose_images/cam1_0.png\")\n",
    "\n",
    "# Draw world frame axes on Camera 0 image\n",
    "draw_axes(img0, R_0_w, T_0_w, K0, dist0)\n",
    "cv2.imshow(\"Camera 0 - World Frame Projection\", img0)\n",
    "\n",
    "# Draw world frame axes on Camera 1 image\n",
    "draw_axes(img1, R_1_w, T_1_w, K1, dist1)\n",
    "cv2.imshow(\"Camera 1 - World Frame Projection\", img1)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "with open(\"../camera_calibration/05-08-25/camera_calib_data.pkl\", \"rb\") as f:\n",
    "    camera_calib = pickle.load(f)\n",
    "\n",
    "K0 = camera_calib[\"cam0\"][\"intrinsics\"][\"K\"]\n",
    "dist0 = camera_calib[\"cam0\"][\"intrinsics\"][\"d\"]\n",
    "R_1_0 = camera_calib[\"stereo_extrinsics\"][\"R_1_0\"]\n",
    "T_1_0 = camera_calib[\"stereo_extrinsics\"][\"T_1_0\"]\n",
    "\n",
    "img_points = np.array([\n",
    "    [317., 117.],\n",
    "    [318., 144.],\n",
    "    [316., 199.],\n",
    "    [308., 118.],\n",
    "    # [278, 148],\n",
    "    # [326, 118],\n",
    "    # [354, 150]\n",
    "], dtype=np.float32)\n",
    "obj_points = 0.001 * np.array([[0, 4.125, 0],\n",
    "                [0, 16, 9],\n",
    "                [0, 0, 23.95],\n",
    "                [-4.125, 0, 0],\n",
    "                # [-16, 0, 9],\n",
    "                # [4.125, 0, 0],\n",
    "                # [16, 0, 9]\n",
    "                ])\n",
    "\n",
    "ret, rvec, tvec, _ = cv2.solvePnPRansac(obj_points, img_points, K0, dist0, flags=cv2.SOLVEPNP_P3P)\n",
    "R0 = cv2.Rodrigues(rvec)[0]\n",
    "T0 = tvec\n",
    "R1 = np.dot(R_1_0, R0)\n",
    "T1 = np.dot(R_1_0, T0) + T_1_0\n",
    "print(\"R1:\\n\", R1)\n",
    "print(\"T1:\\n\", T1)\n",
    "\n",
    "# Update and save camera calibration data\n",
    "camera_calib[\"cam0\"][\"extrinsics\"][\"R\"] = R0\n",
    "camera_calib[\"cam0\"][\"extrinsics\"][\"T\"] = T0\n",
    "camera_calib[\"cam1\"][\"extrinsics\"][\"R\"] = R1\n",
    "camera_calib[\"cam1\"][\"extrinsics\"][\"T\"] = T1\n",
    "\n",
    "with open(f\"../camera_calibration/05-16-25/camera_calib_data.pkl\", \"wb\") as f:\n",
    "    pickle.dump(camera_calib, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize new transform\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "def draw_axes(image, R, T, K, dist):\n",
    "    \"\"\"Draw the world frame origin and axes on the image.\"\"\"\n",
    "    axis_length = 0.05  # 5 cm\n",
    "\n",
    "    # Define the 3D points for the axes\n",
    "    axis_points = np.float32([\n",
    "        [0, 0, 0],              # Origin\n",
    "        [axis_length, 0, 0],    # X-axis (red)\n",
    "        [0, axis_length, 0],    # Y-axis (green)\n",
    "        [0, 0, axis_length]     # Z-axis (blue)\n",
    "    ]).reshape(-1, 3)\n",
    "\n",
    "    # Project the 3D axis points onto the image plane\n",
    "    img_points, _ = cv2.projectPoints(axis_points, cv2.Rodrigues(R)[0], T, K, dist)\n",
    "\n",
    "    # Draw the origin point\n",
    "    origin = tuple(img_points[0].ravel().astype(int))\n",
    "    cv2.circle(image, origin, 5, (0, 0, 255), -1)\n",
    "\n",
    "    # Draw the X, Y, Z axes\n",
    "    cv2.line(image, origin, tuple(img_points[1].ravel().astype(int)), (0, 0, 255), 3)  # X-axis (red)\n",
    "    cv2.line(image, origin, tuple(img_points[2].ravel().astype(int)), (0, 255, 0), 3)  # Y-axis (green)\n",
    "    cv2.line(image, origin, tuple(img_points[3].ravel().astype(int)), (255, 0, 0), 3)  # Z-axis (blue)\n",
    "\n",
    "    # Annotate the axes\n",
    "    cv2.putText(image, \"X\", tuple(img_points[1].ravel().astype(int)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "    cv2.putText(image, \"Y\", tuple(img_points[2].ravel().astype(int)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.putText(image, \"Z\", tuple(img_points[3].ravel().astype(int)), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "with open(f\"../camera_calibration/05-16-25/camera_calib_data.pkl\", \"rb\") as f:\n",
    "    camera_calib = pickle.load(f)\n",
    "\n",
    "K0 = camera_calib[\"cam0\"][\"intrinsics\"][\"K\"]\n",
    "dist0 = camera_calib[\"cam0\"][\"intrinsics\"][\"d\"]\n",
    "R0 = camera_calib[\"cam0\"][\"extrinsics\"][\"R\"]\n",
    "T0 = camera_calib[\"cam0\"][\"extrinsics\"][\"T\"]\n",
    "K1 = camera_calib[\"cam1\"][\"intrinsics\"][\"K\"]\n",
    "dist1 = camera_calib[\"cam1\"][\"intrinsics\"][\"d\"]\n",
    "R1 = camera_calib[\"cam1\"][\"extrinsics\"][\"R\"]\n",
    "T1 = camera_calib[\"cam1\"][\"extrinsics\"][\"T\"]\n",
    "\n",
    "# Load images for verification\n",
    "img0 = cv2.imread(\"../camera_calibration/05-16-25/extrinsic_calib_images/cam0_0.png\")\n",
    "img1 = cv2.imread(\"../camera_calibration/05-16-25/extrinsic_calib_images/cam1_0.png\")\n",
    "# Downsize images for display\n",
    "img0 = cv2.resize(img0, (640, 480))\n",
    "img1 = cv2.resize(img1, (640, 480))\n",
    "\n",
    "# Draw world frame axes on Camera 0 image\n",
    "draw_axes(img0, R0, T0, K0, dist0)\n",
    "cv2.imshow(\"Camera 0 - World Frame Projection\", img0)\n",
    "# Draw world frame axes on Camera 1 image\n",
    "draw_axes(img1, R1, T1, K1, dist1)\n",
    "cv2.imshow(\"Camera 1 - World Frame Projection\", img1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write calibration matrices to python module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# # Load camera calibration data from pkl file\n",
    "# with open(f\"{calib_base_folder}/camera_calib_data.pkl\", \"rb\") as f:\n",
    "#     camera_calib_data = pickle.load(f)\n",
    "\n",
    "# Write to a python module\n",
    "calib_module_path = f\"{calib_base_folder}/camera_calib_data.py\"\n",
    "with open(calib_module_path, \"w\") as f:\n",
    "    f.write(\"# This file is auto-generated from camera calibration data.\\n\")\n",
    "    f.write(\"import numpy as np\\n\\n\")\n",
    "    f.write(f\"K0 = np.{repr(camera_calib_data['cam0']['intrinsics']['K'])}\\n\")\n",
    "    f.write(f\"d0 = np.{repr(camera_calib_data['cam0']['intrinsics']['d'])}\\n\")\n",
    "    f.write(f\"K1 = np.{repr(camera_calib_data['cam1']['intrinsics']['K'])}\\n\")\n",
    "    f.write(f\"d1 = np.{repr(camera_calib_data['cam1']['intrinsics']['d'])}\\n\")\n",
    "    f.write(f\"K2 = np.{repr(camera_calib_data['cam2']['intrinsics']['K'])}\\n\")\n",
    "    f.write(f\"d2 = np.{repr(camera_calib_data['cam2']['intrinsics']['d'])}\\n\")\n",
    "    f.write(f\"R_1_0 = np.{repr(camera_calib_data['stereo_extrinsics']['R_1_0'])}\\n\")\n",
    "    f.write(f\"T_1_0 = np.{repr(camera_calib_data['stereo_extrinsics']['T_1_0'])}\\n\")\n",
    "    f.write(f\"R_0_w = np.{repr(camera_calib_data['cam0']['extrinsics']['R'])}\\n\")\n",
    "    f.write(f\"T_0_w = np.{repr(camera_calib_data['cam0']['extrinsics']['T'])}\\n\")\n",
    "    f.write(f\"R_1_w = np.{repr(camera_calib_data['cam1']['extrinsics']['R'])}\\n\")\n",
    "    f.write(f\"T_1_w = np.{repr(camera_calib_data['cam1']['extrinsics']['T'])}\\n\")\n",
    "    f.write(f\"R_2_1 = np.{repr(camera_calib_data['stereo_extrinsics']['R_2_1'])}\\n\")\n",
    "    f.write(f\"T_2_1 = np.{repr(camera_calib_data['stereo_extrinsics']['T_2_1'])}\\n\")\n",
    "    f.write(f\"R_2_w = np.{repr(camera_calib_data['cam2']['extrinsics']['R'])}\\n\")\n",
    "    f.write(f\"T_2_w = np.{repr(camera_calib_data['cam2']['extrinsics']['T'])}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
