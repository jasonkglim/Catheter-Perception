{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31b7310b",
   "metadata": {},
   "source": [
    "# Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b76d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def calibrate_intrinsics(image_glob, pattern_size=(9,6), square_size=0.025):\n",
    "    \"\"\"\n",
    "    Calibrate a single camera's intrinsics using checkerboard images.\n",
    "    \n",
    "    Args:\n",
    "        image_glob (str): Glob pattern for calibration images.\n",
    "        pattern_size (tuple): Number of inner corners per checkerboard row, col.\n",
    "        square_size (float): Size of a checkerboard square in meters.\n",
    "        \n",
    "    Returns:\n",
    "        ret (float): RMS re-projection error.\n",
    "        K (ndarray): Camera matrix (3x3).\n",
    "        dist (ndarray): Distortion coefficients.\n",
    "        rvecs, tvecs: Extrinsic vectors for each image.\n",
    "    \"\"\"\n",
    "    # Prepare object points (0,0,0), ..., scaled by square_size\n",
    "    objp = np.zeros((pattern_size[0]*pattern_size[1],3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:pattern_size[0], 0:pattern_size[1]].T.reshape(-1,2)\n",
    "    objp *= square_size\n",
    "\n",
    "    objpoints, imgpoints = [], []\n",
    "    images = glob.glob(image_glob)\n",
    "    for fname in images:\n",
    "        img = cv2.imread(fname)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        ret, corners = cv2.findChessboardCorners(gray, pattern_size, None)\n",
    "        if not ret:\n",
    "            continue\n",
    "        corners2 = cv2.cornerSubPix(\n",
    "            gray, corners, (11,11), (-1,-1),\n",
    "            criteria=(cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "        )\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners2)\n",
    "\n",
    "    ret, K, dist, rvecs, tvecs = cv2.calibrateCamera(\n",
    "        objpoints, imgpoints, gray.shape[::-1], None, None\n",
    "    )\n",
    "    print(f\"Intrinsics RMS error: {ret:.4f}\")\n",
    "    return ret, K, dist, rvecs, tvecs\n",
    "\n",
    "def stereo_calibrate(\n",
    "    glob1, glob2, pattern_size, square_size,\n",
    "    K1, d1, K2, d2,\n",
    "    flags=cv2.CALIB_FIX_INTRINSIC\n",
    "):\n",
    "    \"\"\"\n",
    "    Stereo calibrate two cameras that have already been intrinsically calibrated.\n",
    "    \n",
    "    Args:\n",
    "        glob1, glob2: Glob patterns for the two cameras' images.\n",
    "        pattern_size, square_size: Checkerboard parameters.\n",
    "        K1, d1, K2, d2: Intrinsics and distortions for camera 1 and 2.\n",
    "        flags: calibration flags.\n",
    "        \n",
    "    Returns:\n",
    "        R, T, E, F: Rotation, translation, essential and fundamental matrices.\n",
    "    \"\"\"\n",
    "    objp = np.zeros((pattern_size[0]*pattern_size[1],3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:pattern_size[0], 0:pattern_size[1]].T.reshape(-1,2)\n",
    "    objp *= square_size\n",
    "\n",
    "    objpoints, imgpoints1, imgpoints2 = [], [], []\n",
    "    imgs1 = sorted(glob.glob(glob1))\n",
    "    imgs2 = sorted(glob.glob(glob2))\n",
    "    for f1, f2 in zip(imgs1, imgs2):\n",
    "        im1 = cv2.imread(f1); gray1 = cv2.cvtColor(im1, cv2.COLOR_BGR2GRAY)\n",
    "        im2 = cv2.imread(f2); gray2 = cv2.cvtColor(im2, cv2.COLOR_BGR2GRAY)\n",
    "        r1, c1 = cv2.findChessboardCorners(gray1, pattern_size, None)\n",
    "        r2, c2 = cv2.findChessboardCorners(gray2, pattern_size, None)\n",
    "        if not (r1 and r2):\n",
    "            continue\n",
    "        c1 = cv2.cornerSubPix(\n",
    "            gray1, c1, (11,11), (-1,-1),\n",
    "            (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "        )\n",
    "        c2 = cv2.cornerSubPix(\n",
    "            gray2, c2, (11,11), (-1,-1),\n",
    "            (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "        )\n",
    "        objpoints.append(objp)\n",
    "        imgpoints1.append(c1)\n",
    "        imgpoints2.append(c2)\n",
    "\n",
    "    ret, _, _, _, _, R, T, E, F = cv2.stereoCalibrate(\n",
    "        objpoints, imgpoints1, imgpoints2,\n",
    "        K1, d1, K2, d2,\n",
    "        gray1.shape[::-1],\n",
    "        criteria=(cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 1e-5),\n",
    "        flags=flags\n",
    "    )\n",
    "    print(f\"Stereo RMS error: {ret:.4f}\")\n",
    "    return R, T, E, F\n",
    "\n",
    "def calibrate_camera_to_world(\n",
    "    image_glob, world_objpoints=None,\n",
    "    pattern_size=(9,6), square_size=0.025,\n",
    "    K=None, dist=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Solve PnP to get camera-to-world extrinsics using a known world marker.\n",
    "    \n",
    "    Args:\n",
    "        image_glob: Glob for images where the world marker is visible.\n",
    "        world_objpoints: (N×3) array of 3D points in world coords.\n",
    "        pattern_size, square_size: if using a checkerboard as your world frame.\n",
    "        K, dist: intrinsic calibration for this camera.\n",
    "        \n",
    "    Returns:\n",
    "        rvec, tvec: rotation and translation from world to camera.\n",
    "    \"\"\"\n",
    "    if world_objpoints is None:\n",
    "        wp = np.zeros((pattern_size[0]*pattern_size[1],3), np.float32)\n",
    "        wp[:,:2] = np.mgrid[0:pattern_size[0], 0:pattern_size[1]].T.reshape(-1,2)\n",
    "        wp *= square_size\n",
    "        world_objpoints = wp\n",
    "\n",
    "    for fname in glob.glob(image_glob):\n",
    "        img = cv2.imread(fname)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        ret, corners = cv2.findChessboardCorners(gray, pattern_size, None)\n",
    "        if not ret:\n",
    "            continue\n",
    "        corners2 = cv2.cornerSubPix(\n",
    "            gray, corners, (11,11), (-1,-1),\n",
    "            (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "        )\n",
    "        ret, rvec, tvec = cv2.solvePnP(world_objpoints, corners2, K, dist)\n",
    "        if ret:\n",
    "            proj, _ = cv2.projectPoints(world_objpoints, rvec, tvec, K, dist)\n",
    "            err = np.linalg.norm(corners2.reshape(-1,2) - proj.reshape(-1,2)) / len(proj)\n",
    "            print(f\"SolvePnP reprojection error: {err*1e3:.2f} mm\")\n",
    "            return rvec, tvec\n",
    "    raise RuntimeError(\"Marker not detected in any image\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 1) Intrinsics\n",
    "    _, K1, d1, _, _ = calibrate_intrinsics(\"calib_images/cam1/*.png\")\n",
    "    _, K2, d2, _, _ = calibrate_intrinsics(\"calib_images/cam2/*.png\")\n",
    "    \n",
    "    # 2) Stereo extrinsics\n",
    "    R, T, E, F = stereo_calibrate(\n",
    "        \"calib_images/cam1/*.png\", \"calib_images/cam2/*.png\",\n",
    "        pattern_size=(9,6), square_size=0.025,\n",
    "        K1=K1, d1=d1, K2=K2, d2=d2\n",
    "    )\n",
    "    \n",
    "    # 3) Camera-to-world\n",
    "    rvec1, tvec1 = calibrate_camera_to_world(\n",
    "        \"marker_images/cam1/*.png\", None,\n",
    "        pattern_size=(9,6), square_size=0.025,\n",
    "        K=K1, dist=d1\n",
    "    )\n",
    "    rvec2, tvec2 = calibrate_camera_to_world(\n",
    "        \"marker_images/cam2/*.png\", None,\n",
    "        pattern_size=(9,6), square_size=0.025,\n",
    "        K=K2, dist=d2\n",
    "    )\n",
    "    \n",
    "    print(\"Calibration complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785abc0b",
   "metadata": {},
   "source": [
    "# Pose Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4b4fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def back_project(coord, camera_number):\n",
    "    \"\"\"\n",
    "    Back-project a 3D point to 2D pixel coordinates in the image plane.\n",
    "    \n",
    "    Args:\n",
    "        coord: 3D point in world coordinates.\n",
    "        camera_number: 0 for left camera, 1 for right camera.\n",
    "        \n",
    "    Returns:\n",
    "        pixel_coord: 2D pixel coordinates in the image plane.\n",
    "    \"\"\"\n",
    "    # Camera intrinsics and extrinsics (example values)\n",
    "    K = np.array([[1000, 0, 320],\n",
    "                  [0, 1000, 240],\n",
    "                  [0, 0, 1]])\n",
    "    R = np.eye(3) if camera_number == 0 else np.array([[0, -1, 0], [1, 0, 0], [0, 0, 1]])\n",
    "    T = np.array([0.5, 0, 0]) if camera_number == 1 else np.array([0, 0, 0])\n",
    "    \n",
    "    # Project the point\n",
    "    coord_homogeneous = np.append(coord, 1) # Convert to homogeneous coordinates\n",
    "    pixel_coord_homogeneous = K @ (R @ coord_homogeneous + T)\n",
    "    pixel_coord = pixel_coord_homogeneous[:2] / pixel_coord_homogeneous[2]\n",
    "    \n",
    "    return pixel_coord\n",
    "\n",
    "# 1) Create lookup table for voxel grid\n",
    "Nx, Ny, Nz = 20, 20, 20\n",
    "origin = np.array([0, 0, 0])\n",
    "voxel_size = np.array([0.01, 0.01, 0.01])\n",
    "lookup_table = np.zeros((Nx, Ny, Nz, 2, 2), dtype=np.float32)\n",
    "for x in range(Nx):\n",
    "    for y in range(Ny):\n",
    "        for z in range(Nz):\n",
    "            coord = origin + np.array([x, y, z]) * voxel_size\n",
    "            for camera_number in range(2):\n",
    "                pixel_coord = back_project(coord, camera_number)\n",
    "                lookup_table[x, y, z, camera_number] = np.reshape(pixel_coord, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6062e596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Obtain masks for left and right cameras\n",
    "# TODO: Replace with actual image loading and processing\n",
    "mask_0 = np.zeros((480, 640), dtype=np.uint8)\n",
    "mask_1 = np.zeros((480, 640), dtype=np.uint8)\n",
    "\n",
    "# 3) Voxel carving: keep (x,y,z) if both silhouettes agree\n",
    "volume = np.zeros((Nx, Ny, Nz), dtype=np.uint8)\n",
    "for x in range(Nx):\n",
    "    for y in range(Ny):\n",
    "        for z in range(Nz):\n",
    "            pixel_coord_0 = lookup_table[x, y, z, 0]\n",
    "            pixel_coord_1 = lookup_table[x, y, z, 1]\n",
    "            if mask_0[pixel_coord_0[0], pixel_coord_0[1]] and \\\n",
    "               mask_1[pixel_coord_1[0], pixel_coord_1[1]]:\n",
    "                volume[x, y, z] = 1\n",
    "                \n",
    "points = np.argwhere(volume == 1)  # Get indices of carved voxels\n",
    "                \n",
    "\n",
    "# 4) Compute a simple centerline: for each z-slice, average x & y\n",
    "centerline = []\n",
    "for zk in z:\n",
    "    slice_pts = points[np.isclose(points[:, 2], zk)]\n",
    "    if len(slice_pts) > 0:\n",
    "        cx, cy = slice_pts[:,0].mean(), slice_pts[:,1].mean()\n",
    "        centerline.append([cx, cy, zk])\n",
    "centerline = np.array(centerline)\n",
    "\n",
    "# 5) Estimate tangent at the tip (last two points)\n",
    "v = centerline[-1] - centerline[-2]\n",
    "theta = np.arccos(v[2] / np.linalg.norm(v))  # bending magnitude\n",
    "phi   = np.arctan2(v[1], v[0])              # bending plane\n",
    "\n",
    "print(\"Estimated bending angle θ (rad):\", theta)\n",
    "print(\"Estimated bending plane φ (rad):\", phi)\n",
    "\n",
    "# 6) Plot a 2D x–z view of the carved voxels and the centerline\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(points[:,0], points[:,2], marker='.', label='voxels')\n",
    "ax.plot(centerline[:,0], centerline[:,2], label='centerline')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('z')\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0475980",
   "metadata": {},
   "source": [
    "# Create Charuco board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28669331",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'cv2.aruco.CharucoBoard' object has no attribute 'draw'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 17\u001b[0m\n\u001b[0;32m     10\u001b[0m charuco_board \u001b[38;5;241m=\u001b[39m aruco\u001b[38;5;241m.\u001b[39mCharucoBoard(\n\u001b[0;32m     11\u001b[0m     (\u001b[38;5;241m11\u001b[39m, \u001b[38;5;241m8\u001b[39m),\n\u001b[0;32m     12\u001b[0m     squareLength\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.015\u001b[39m, markerLength\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.011\u001b[39m,\n\u001b[0;32m     13\u001b[0m     dictionary\u001b[38;5;241m=\u001b[39maruco_dict\n\u001b[0;32m     14\u001b[0m )\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# 3. Draw & save an image of the board at 200 DPI\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m img \u001b[38;5;241m=\u001b[39m charuco_board\u001b[38;5;241m.\u001b[39mdraw((\u001b[38;5;241m2000\u001b[39m, \u001b[38;5;241m1500\u001b[39m))\n\u001b[0;32m     18\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcharuco_board.png\u001b[39m\u001b[38;5;124m\"\u001b[39m, img)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'cv2.aruco.CharucoBoard' object has no attribute 'draw'"
     ]
    }
   ],
   "source": [
    "import cv2, cv2.aruco as aruco\n",
    "import numpy as np\n",
    "\n",
    "# print([n for n in dir(cv2.aruco) if n.startswith(\"DICT\")])\n",
    "\n",
    "# 1. Choose your ArUco dictionary\n",
    "aruco_dict = aruco.getPredefinedDictionary(aruco.DICT_4X4_50)\n",
    "\n",
    "# 2. Create a ChArUco board: 7×5 chessboard squares, each square = 0.04 m, marker length = 0.03 m\n",
    "charuco_board = aruco.CharucoBoard(\n",
    "    (11, 8),\n",
    "    squareLength=0.015, markerLength=0.011,\n",
    "    dictionary=aruco_dict\n",
    ")\n",
    "\n",
    "# 3. Draw & save an image of the board at 200 DPI\n",
    "img = charuco_board.draw((2000, 1500))\n",
    "cv2.imwrite(\"charuco_board.png\", img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
